{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import the necessary files"
      ],
      "metadata": {
        "id": "Ej6po8g8v8Iw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsZ_FQQPEDCl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3O4i5idkwC2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pandarallel is a simple and efficient tool to parallelize Pandas operations on all available CPUs"
      ],
      "metadata": {
        "id": "M7qQyGkxwJS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvJ_hUN0Y7nk",
        "outputId": "18f7c1ed-10cf-4f7f-bbcb-39de43d1455e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandarallel\n",
            "  Downloading pandarallel-1.6.5.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dill>=0.3.1 (from pandarallel)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1 in /usr/local/lib/python3.10/dist-packages (from pandarallel) (2.0.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from pandarallel) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\n",
            "Building wheels for collected packages: pandarallel\n",
            "  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandarallel: filename=pandarallel-1.6.5-py3-none-any.whl size=16673 sha256=dd793eb25a50fe9eccd4c5f7c0500afb657e7db8d26f9cc3452e0f3deea6f931\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/4f/1e/34e057bb868842209f1623f195b74fd7eda229308a7352d47f\n",
            "Successfully built pandarallel\n",
            "Installing collected packages: dill, pandarallel\n",
            "Successfully installed dill-0.3.8 pandarallel-1.6.5\n",
            "INFO: Pandarallel will run on 1 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
          ]
        }
      ],
      "source": [
        "!pip install pandarallel\n",
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mounting the gdrive"
      ],
      "metadata": {
        "id": "LSzREfTFwLK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXrbh5N-yRV3",
        "outputId": "13ee4614-53f3-40ce-e24c-a2274dbb49e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glb3kcxknQLB",
        "outputId": "040113b4-1c61-4a64-9893-0bd83bddca7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1oh9c-d0fo3NtETNySmCNLUc6H1j4dSWE subtaskB_dev.jsonl\n",
            "Processing file 1k5LMwmYF7PF-BzYQNE2ULBae79nbM268 subtaskB_train.jsonl\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oh9c-d0fo3NtETNySmCNLUc6H1j4dSWE\n",
            "To: /content/SubtaskB/subtaskB_dev.jsonl\n",
            "100% 4.93M/4.93M [00:00<00:00, 76.9MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1k5LMwmYF7PF-BzYQNE2ULBae79nbM268\n",
            "From (redirected): https://drive.google.com/uc?id=1k5LMwmYF7PF-BzYQNE2ULBae79nbM268&confirm=t&uuid=f61a71fd-733a-4eb6-96da-814834cbd3ae\n",
            "To: /content/SubtaskB/subtaskB_train.jsonl\n",
            "100% 155M/155M [00:00<00:00, 184MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!gdown --folder https://drive.google.com/drive/folders/11YeloR2eTXcTzdwI04Z-M2QVvIeQAU6-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PDNdNkddoie_",
        "outputId": "27f22f78-6a25-42c2-ac8b-416bed71cac1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/SubtaskB'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Source and Destination Paths\n",
        "source_folder = \"/content/SubtaskB\"  # Change this to your source folder path\n",
        "destination_folder = \"/content/drive/MyDrive/SubtaskB\"  # Change this to your destination folder path\n",
        "\n",
        "# Copy Files\n",
        "shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5ZjuIGiD_Qn"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "with open(\"/content/drive/My Drive/SubtaskA/subtaskA_train_monolingual.jsonl\", \"r\") as file:\n",
        "    for line in file:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "df = pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUGENYhRPeer"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "with open(\"/content/drive/MyDrive/SubtaskB/subtaskb.jsonl\", \"r\") as file:\n",
        "    for line in file:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "test = pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIastKrcqPTz"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "with open(\"/content/drive/My Drive/SubtaskB/subtaskB_train.jsonl\", \"r\") as file:\n",
        "    for line in file:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "dfbtrain = pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Etrdq0mqYg5"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "with open(\"/content/drive/My Drive/SubtaskB/subtaskB_dev.jsonl\", \"r\") as file:\n",
        "    for line in file:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "dfbdev = pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg4tD9yBahfQ"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/SubtaskB/dfbtrain_enron.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5_9rV1w8vB7K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoHc4CctPxFR",
        "outputId": "7da0a120-75a8-474f-98aa-4e7729a09324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  id\n",
            "0  Today, many adults or teenage drivers are hook...   0\n",
            "1  The automobile, since its advent, has revoluti...   1\n",
            "2   One policy that could potentially improve aca...   2\n",
            "3  Title: Navigating the Road Ahead: The Case for...   3\n"
          ]
        }
      ],
      "source": [
        "print(test.head(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "4BK1RO-U3zGq",
        "outputId": "a4b7c3e2-8f4b-4b05-948d-1a18280aa1ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8e12da26-4627-4dc0-b147-6c70d9d52d70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>model</th>\n",
              "      <th>source</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "      <th>content_tfidf</th>\n",
              "      <th>avg_len</th>\n",
              "      <th>len_text</th>\n",
              "      <th>len_words</th>\n",
              "      <th>num_short_w</th>\n",
              "      <th>...</th>\n",
              "      <th>f_e_3</th>\n",
              "      <th>f_e_4</th>\n",
              "      <th>f_e_5</th>\n",
              "      <th>f_e_6</th>\n",
              "      <th>f_e_7</th>\n",
              "      <th>f_e_8</th>\n",
              "      <th>f_e_9</th>\n",
              "      <th>f_e_10</th>\n",
              "      <th>f_e_11</th>\n",
              "      <th>richness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Forza Motorsport is a popular racing game that...</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>forza motorsport popular race game provid play...</td>\n",
              "      <td>4.457002</td>\n",
              "      <td>2244.0</td>\n",
              "      <td>407.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015152</td>\n",
              "      <td>0.014706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.577396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Buying Virtual Console games for your Nintendo...</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>buy virtual consol game nintendo wii fun easi ...</td>\n",
              "      <td>4.418502</td>\n",
              "      <td>3728.0</td>\n",
              "      <td>681.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017972</td>\n",
              "      <td>0.006706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003219</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.427313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Windows NT 4.0 was a popular operating system ...</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>window nt 4.0 wa popular oper system back day ...</td>\n",
              "      <td>4.709748</td>\n",
              "      <td>5237.0</td>\n",
              "      <td>913.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020432</td>\n",
              "      <td>0.005728</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001146</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.346112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How to Make Perfume\\n\\nPerfume is a great way ...</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>make perfum perfum great way enhanc person sce...</td>\n",
              "      <td>4.772277</td>\n",
              "      <td>4729.0</td>\n",
              "      <td>808.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014168</td>\n",
              "      <td>0.005709</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002326</td>\n",
              "      <td>0.002326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.407178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to Convert Song Lyrics to a Song'\\n\\nConve...</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>convert song lyric song' convert song lyric fu...</td>\n",
              "      <td>4.407733</td>\n",
              "      <td>3095.0</td>\n",
              "      <td>569.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.012601</td>\n",
              "      <td>0.008401</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.427065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e12da26-4627-4dc0-b147-6c70d9d52d70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e12da26-4627-4dc0-b147-6c70d9d52d70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e12da26-4627-4dc0-b147-6c70d9d52d70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2463991c-28a1-4895-b81f-7dc63a8be2ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2463991c-28a1-4895-b81f-7dc63a8be2ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2463991c-28a1-4895-b81f-7dc63a8be2ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text    model   source  label  \\\n",
              "0  Forza Motorsport is a popular racing game that...  chatGPT  wikihow      1   \n",
              "1  Buying Virtual Console games for your Nintendo...  chatGPT  wikihow      1   \n",
              "2  Windows NT 4.0 was a popular operating system ...  chatGPT  wikihow      1   \n",
              "3  How to Make Perfume\\n\\nPerfume is a great way ...  chatGPT  wikihow      1   \n",
              "4  How to Convert Song Lyrics to a Song'\\n\\nConve...  chatGPT  wikihow      1   \n",
              "\n",
              "   id                                      content_tfidf   avg_len  len_text  \\\n",
              "0   0  forza motorsport popular race game provid play...  4.457002    2244.0   \n",
              "1   1  buy virtual consol game nintendo wii fun easi ...  4.418502    3728.0   \n",
              "2   2  window nt 4.0 wa popular oper system back day ...  4.709748    5237.0   \n",
              "3   3  make perfum perfum great way enhanc person sce...  4.772277    4729.0   \n",
              "4   4  convert song lyric song' convert song lyric fu...  4.407733    3095.0   \n",
              "\n",
              "   len_words  num_short_w  ...     f_e_3     f_e_4     f_e_5  f_e_6     f_e_7  \\\n",
              "0      407.0         82.0  ...  0.000000  0.015152  0.014706    0.0  0.000891   \n",
              "1      681.0        121.0  ...  0.000000  0.017972  0.006706    0.0  0.003219   \n",
              "2      913.0        159.0  ...  0.000000  0.020432  0.005728    0.0  0.001146   \n",
              "3      808.0        127.0  ...  0.000000  0.014168  0.005709    0.0  0.001269   \n",
              "4      569.0        116.0  ...  0.000646  0.012601  0.008401    0.0  0.003877   \n",
              "\n",
              "      f_e_8     f_e_9    f_e_10  f_e_11  richness  \n",
              "0  0.000000  0.000000  0.000000     0.0  0.577396  \n",
              "1  0.000000  0.000000  0.000000     0.0  0.427313  \n",
              "2  0.000382  0.000191  0.000191     0.0  0.346112  \n",
              "3  0.000000  0.002326  0.002326     0.0  0.407178  \n",
              "4  0.000000  0.000646  0.000646     0.0  0.427065  \n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfbtrain.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKoj7qly4EpQ",
        "outputId": "1247fb72-5151-405e-b5a8-e86870f16432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3    11999\n",
            "4    11998\n",
            "0    11997\n",
            "1    11995\n",
            "5    11702\n",
            "2    11336\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'label_column' is the column containing the labels\n",
        "# For example:\n",
        "# df = pd.read_csv(\"your_data.csv\")\n",
        "# label_column = \"label\"\n",
        "\n",
        "# Count of labels\n",
        "label_counts = dfbtrain[\"label\"].value_counts()\n",
        "\n",
        "print(label_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eRNDwkIBch3",
        "outputId": "f229012a-afa4-4503-a87e-9f97ae83bcb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique labels: 6\n"
          ]
        }
      ],
      "source": [
        " # Count of unique labels\n",
        "num_unique_labels = dfbtrain[\"label\"].nunique()\n",
        "\n",
        "print(\"Number of unique labels:\", num_unique_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txt6JbVtq2Xk",
        "outputId": "2462ceb6-4e75-4067-af29-663367d2781b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "71027"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dfbtrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJVpD5XJq6yR",
        "outputId": "74cfc90a-6ff7-4edb-97f8-b89afd19667b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dfbdev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YNXk7pZP0aF",
        "outputId": "7f362752-b01d-4d40-8c07-c2b8b9f61286"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "34272"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_er9A62vEOWI",
        "outputId": "9c99df52-1192-4a72-fa12-f451d1bc4faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  label    model   source  \\\n",
            "0  Forza Motorsport is a popular racing game that...      1  chatGPT  wikihow   \n",
            "1  Buying Virtual Console games for your Nintendo...      1  chatGPT  wikihow   \n",
            "2  Windows NT 4.0 was a popular operating system ...      1  chatGPT  wikihow   \n",
            "3  How to Make Perfume\\n\\nPerfume is a great way ...      1  chatGPT  wikihow   \n",
            "\n",
            "   id  \n",
            "0   0  \n",
            "1   1  \n",
            "2   2  \n",
            "3   3  \n"
          ]
        }
      ],
      "source": [
        "print(df.head(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaiH8aTA1m6f"
      },
      "outputs": [],
      "source": [
        "source_path = '/content/fine_tuned_model/'  # Colab local file path\n",
        "destination_path = '/content/drive/My Drive/fine_tuned_model/'  # Google Drive file path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hV0Vp-l1u6R"
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "# import os\n",
        "# # Copy the file from Colab to Google Drive\n",
        "# files = os.listdir(source_path)\n",
        "# for file in files:\n",
        "#     source_name = os.path.join(source_path,file)\n",
        "#     destination_name = os.path.join(destination_path,file)\n",
        "#     shutil.copy2(source_name, destination_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahN5LELzyvA7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS12gbmWye3h"
      },
      "outputs": [],
      "source": [
        "devdata = []\n",
        "with open(\"/content/drive/My Drive/SubtaskA/subtaskA_dev_monolingual.jsonl\", \"r\") as file:\n",
        "    for line in file:\n",
        "        devdata.append(json.loads(line))\n",
        "\n",
        "dfdev = pd.DataFrame(devdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PTUy-5sy9Ea"
      },
      "outputs": [],
      "source": [
        "# Assuming your DataFrame is named df and the text column is named 'text'\n",
        "\n",
        "# Step 1: Text Cleaning\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove special characters, punctuation, and symbols\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "#df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "# dfdev['cleaned_text'] = dfdev['text'].apply(clean_text)\n",
        "# df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "test['cleaned_text'] = test['text'].apply(clean_text)\n",
        "test['cleaned_text'] = test['cleaned_text'].str.lower()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Lowercasing\n",
        "#df['cleaned_text'] = df['cleaned_text'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IX2zoYd0iLs",
        "outputId": "9665a2f4-bed1-4595-dc84-c66eae671022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing classifier and tokenizer from the transformers"
      ],
      "metadata": {
        "id": "v94hTWftwSqI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF5sp99ezF1r"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
        "\n",
        "model1 = RobertaForSequenceClassification.from_pretrained('/content/drive/My Drive/fine_tuned_model/')\n",
        "tokenizer = RobertaTokenizer.from_pretrained('/content/drive/My Drive/fine_tuned_model/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHOpHJNyzPSW"
      },
      "outputs": [],
      "source": [
        "# Assuming df_dev contains your dev dataset and 'text' is the column name with text data\n",
        "dev_texts = train['cleaned_text'].tolist()\n",
        "\n",
        "# Tokenize the texts\n",
        "inputs = tokenizer(dev_texts, return_tensors='pt', padding=True, truncation=True,max_length=512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0naqlk00bluz"
      },
      "outputs": [],
      "source": [
        "# Assuming df_dev contains your dev dataset and 'text' is the column name with text data\n",
        "trained_texts = df['cleaned_text'].tolist()\n",
        "\n",
        "# Tokenize the texts\n",
        "inputs1 = tokenizer(trained_texts, return_tensors='pt', padding=True, truncation=True,max_length=512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32_FxlYV8KYM"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPxXJkcUzThv"
      },
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48XTXIUvOIfo",
        "outputId": "498a40a2-19c5-4041-a26c-b964ef1da646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: apex in /usr/local/lib/python3.10/dist-packages/apex-0.1-py3.10.egg (0.1)\n",
            "Requirement already satisfied: packaging>20.6 in /usr/local/lib/python3.10/dist-packages (from apex) (23.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNeIY4M9RMqo"
      },
      "outputs": [],
      "source": [
        "dev_labels = dfdev['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13Rknhz5enQw"
      },
      "outputs": [],
      "source": [
        "df_labels = df['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQNZ-8WiQbKU",
        "outputId": "34b070bf-8ffb-469f-becd-9ec990e752c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-6fc2490e7d4f>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(inputs['input_ids']),\n",
            "<ipython-input-21-6fc2490e7d4f>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(inputs['attention_mask']),\n"
          ]
        }
      ],
      "source": [
        "dev_data = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(inputs['input_ids']),\n",
        "    torch.tensor(inputs['attention_mask']),\n",
        "    torch.tensor(dev_labels)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVeSmk-1ej6A",
        "outputId": "fbeb6ed5-9a4a-407a-a06d-97c17e92bcb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-d0c68829c42d>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(inputs1['input_ids']),\n",
            "<ipython-input-22-d0c68829c42d>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch.tensor(inputs1['attention_mask']),\n"
          ]
        }
      ],
      "source": [
        "train_data = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(inputs1['input_ids']),\n",
        "    torch.tensor(inputs1['attention_mask']),\n",
        "    torch.tensor(df_labels)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ed-HynDOlBR",
        "outputId": "800c9cfb-0ae7-48e7-bb43-984af201fd43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: apex 0.1\n",
            "Uninstalling apex-0.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/apex-0.1-py3.10.egg\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled apex-0.1\n",
            "fatal: destination path 'apex' already exists and is not an empty directory.\n",
            "\n",
            "\n",
            "torch.__version__  = 2.0.1+cu118\n",
            "\n",
            "\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing apex.egg-info/PKG-INFO\n",
            "writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "writing requirements to apex.egg-info/requires.txt\n",
            "writing top-level names to apex.egg-info/top_level.txt\n",
            "reading manifest file 'apex.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/fused_dense\n",
            "copying build/lib/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/egg/apex/fused_dense\n",
            "copying build/lib/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/egg/apex/fused_dense\n",
            "creating build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n",
            "copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n",
            "copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/clip_grad\n",
            "copying build/lib/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/clip_grad\n",
            "copying build/lib/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/egg/apex/contrib/clip_grad\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "copying build/lib/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n",
            "copying build/lib/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n",
            "copying build/lib/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn\n",
            "copying build/lib/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn\n",
            "copying build/lib/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n",
            "copying build/lib/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n",
            "copying build/lib/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n",
            "copying build/lib/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n",
            "copying build/lib/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n",
            "copying build/lib/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/fmha\n",
            "copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n",
            "copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/group_norm\n",
            "copying build/lib/apex/contrib/group_norm/group_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/group_norm\n",
            "copying build/lib/apex/contrib/group_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/group_norm\n",
            "copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm\n",
            "copying build/lib/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm\n",
            "copying build/lib/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad\n",
            "copying build/lib/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad\n",
            "copying build/lib/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n",
            "copying build/lib/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n",
            "copying build/lib/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n",
            "copying build/lib/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/transducer\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n",
            "copying build/lib/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n",
            "copying build/lib/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n",
            "copying build/lib/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss\n",
            "copying build/lib/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss\n",
            "copying build/lib/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn\n",
            "copying build/lib/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn\n",
            "copying build/lib/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu\n",
            "copying build/lib/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu\n",
            "copying build/lib/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory\n",
            "copying build/lib/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory\n",
            "copying build/lib/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/fmha\n",
            "copying build/lib/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/fmha\n",
            "copying build/lib/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/fmha\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm\n",
            "copying build/lib/apex/contrib/test/group_norm/test_group_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm\n",
            "copying build/lib/apex/contrib/test/group_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm\n",
            "copying build/lib/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d\n",
            "copying build/lib/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d\n",
            "copying build/lib/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck\n",
            "copying build/lib/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck\n",
            "copying build/lib/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "copying build/lib/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy\n",
            "copying build/lib/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy\n",
            "copying build/lib/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n",
            "copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d\n",
            "copying build/lib/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d\n",
            "copying build/lib/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "creating build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "creating build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "creating build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n",
            "copying build/lib/apex/_autocast_utils.py -> build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/functional\n",
            "copying build/lib/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/egg/apex/transformer/functional\n",
            "copying build/lib/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/functional\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "copying build/lib/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/_data\n",
            "copying build/lib/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/egg/apex/transformer/_data\n",
            "copying build/lib/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/_data\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n",
            "copying build/lib/apex/transformer/_ucc_util.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "copying build/lib/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n",
            "copying build/lib/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "copying build/lib/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "copying build/lib/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n",
            "copying build/lib/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "copying build/lib/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "copying build/lib/apex/transformer/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "copying build/lib/apex/transformer/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/amp\n",
            "copying build/lib/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/egg/apex/transformer/amp\n",
            "copying build/lib/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/amp\n",
            "copying build/lib/apex/transformer/enums.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "creating build/bdist.linux-x86_64/egg/apex/transformer/layers\n",
            "copying build/lib/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/egg/apex/transformer/layers\n",
            "copying build/lib/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/layers\n",
            "copying build/lib/apex/transformer/log_util.py -> build/bdist.linux-x86_64/egg/apex/transformer\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fused_dense/fused_dense.py to fused_dense.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fused_dense/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_mixed_precision_lamb.py to fused_mixed_precision_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_lamb.py to fused_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_novograd.py to fused_novograd.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_sgd.py to fused_sgd.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/clip_grad/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/clip_grad/clip_grad.py to clip_grad.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/transducer.py to transducer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/_transducer_ref.py to _transducer_ref.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/focal_loss/focal_loss.py to focal_loss.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/focal_loss/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn/batch_norm.py to batch_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/cudnn_gbn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu/conv_bias_relu.py to conv_bias_relu.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/peer_halo_exchanger_1d.py to peer_halo_exchanger_1d.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/peer_memory.py to peer_memory.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/fmha.py to fmha.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/group_norm/group_norm.py to group_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/group_norm/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/layer_norm/test_fast_layer_norm.py to test_fast_layer_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/clip_grad/test_clip_grad.py to test_clip_grad.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/transducer/test_transducer_loss.py to test_transducer_loss.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/transducer/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/transducer/test_transducer_joint.py to test_transducer_joint.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers/test_distributed_fused_lamb.py to test_distributed_fused_lamb.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers/test_dist_adam.py to test_dist_adam.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/optimizers/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss/test_focal_loss.py to test_focal_loss.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/focal_loss/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py to test_cudnn_gbn_with_two_gpus.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/cudnn_gbn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py to test_conv_bias_relu.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py to test_peer_halo_exchange_module.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/fmha/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/fmha/test_fmha.py to test_fmha.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm/test_group_norm.py to test_group_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/group_norm/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/index_mul_2d/test_index_mul_2d.py to test_index_mul_2d.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck/test_bottleneck_module.py to test_bottleneck_module.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/bottleneck/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py to test_self_multihead_attn_norm_add.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_self_multihead_attn.py to test_self_multihead_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py to test_mha_fused_softmax.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py to test_encdec_multihead_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py to test_fast_self_multihead_attn_bias.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py to test_encdec_multihead_attn_norm_add.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/test/xentropy/test_label_smoothing.py to test_label_smoothing.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_lib.py to permutation_lib.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py to permutation_utilities.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py to channel_swap.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py to exhaustive_search.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py to call_permutation_search_kernels.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/asp.py to asp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d/index_mul_2d.py to index_mul_2d.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/index_mul_2d/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/halo_exchangers.py to halo_exchangers.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/test.py to test.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/_autocast_utils.py to _autocast_utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/mlp.py to mlp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/functional/fused_softmax.py to fused_softmax.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/functional/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/mappings.py to mappings.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/random.py to random.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/data.py to data.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/layers.py to layers.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/memory.py to memory.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/cross_entropy.py to cross_entropy.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_data/_batchsampler.py to _batchsampler.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_data/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_transformer_lm.py to standalone_transformer_lm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/global_vars.py to global_vars.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/arguments.py to arguments.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_bert.py to standalone_bert.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_gpt.py to standalone_gpt.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/distributed_test_base.py to distributed_test_base.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/commons.py to commons.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_ucc_util.py to _ucc_util.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/p2p_communication.py to p2p_communication.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py to fwd_bwd_pipelining_with_interleaving.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py to fwd_bwd_no_pipelining.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/common.py to common.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py to fwd_bwd_pipelining_without_interleaving.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/_timers.py to _timers.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/parallel_state.py to parallel_state.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/microbatches.py to microbatches.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/utils.py to utils.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/amp/grad_scaler.py to grad_scaler.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/amp/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/enums.py to enums.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/layers/layer_norm.py to layer_norm.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/layers/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/log_util.py to log_util.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "apex.contrib.optimizers.__pycache__.distributed_fused_adam.cpython-310: module MAY be using inspect.stack\n",
            "creating 'dist/apex-0.1-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing apex-0.1-py3.10.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/apex-0.1-py3.10.egg\n",
            "Extracting apex-0.1-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding apex 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/apex-0.1-py3.10.egg\n",
            "Processing dependencies for apex==0.1\n",
            "Searching for packaging==23.1\n",
            "Best match: packaging 23.1\n",
            "Adding packaging 23.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for apex==0.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall apex\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "!cd apex && python setup.py install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzvityW8RtwW"
      },
      "outputs": [],
      "source": [
        "dev_loader = torch.utils.data.DataLoader(dev_data, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62K5uur0cmh5"
      },
      "outputs": [],
      "source": [
        "df_loader = torch.utils.data.DataLoader(train_data, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifKinVGxScQO"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stqVLoknT15K",
        "outputId": "fa1ed88b-50bb-4bac-e00d-7f8fc98aa04b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd5_h-s9GbOz",
        "outputId": "40e678f3-1c46-471f-9dff-0dceef3c5747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 79.12%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "model1.eval()\n",
        "total_correct = 0\n",
        "all_predictions = []\n",
        "all_actual_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in dev_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        total_correct += (predictions == labels).sum().item()\n",
        "\n",
        "        # Save predictions and actual labels for each batch\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "        all_actual_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = total_correct / len(dev_loader.dataset)\n",
        "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Convert predictions and actual labels to a pandas DataFrame\n",
        "df = pd.DataFrame({'Prediction': all_predictions, 'ActualLabel': all_actual_labels})\n",
        "\n",
        "# Save DataFrame to Excel\n",
        "df.to_excel('predictions_with_actual_labels.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDNIGkE3ap28"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# Function to get logits from a model\n",
        "def get_logits(model, dataloader):\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids, attention_mask, _ = batch\n",
        "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits.cpu().numpy()\n",
        "            all_logits.extend(logits)\n",
        "\n",
        "    return all_logits\n",
        "\n",
        "# Get logits for dev data\n",
        "dev_logits = get_logits(model1, dev_loader)\n",
        "\n",
        "# Save logits to a pickle file\n",
        "with open('/content/drive/MyDrive/SubtaskA/dev_logits.pkl', 'wb') as f:\n",
        "    pickle.dump(dev_logits, f)\n",
        "\n",
        "# Convert logits to a pandas DataFrame\n",
        "df_dev_logits = pd.DataFrame(dev_logits, columns=[f'logit_{i}' for i in range(len(dev_logits[0]))])\n",
        "\n",
        "# Save DataFrame to Excel\n",
        "df_dev_logits.to_excel('dev_logits_dataframe.xlsx', index=False)\n",
        "\n",
        "\n",
        "train_logits = get_logits(model1, df_loader)\n",
        "\n",
        "\n",
        "\n",
        "# Save logits to a pickle file\n",
        "with open('/content/drive/MyDrive/SubtaskA/train_logits.pkl', 'wb') as f:\n",
        "    pickle.dump(train_logits, f)\n",
        "\n",
        "# Convert logits to a pandas DataFrame\n",
        "df_train_logits = pd.DataFrame(train_logits, columns=[f'logit_{i}' for i in range(len(train_logits[0]))])\n",
        "\n",
        "# Save DataFrame to Excel\n",
        "df_train_logits.to_excel('train_logits_dataframe.xlsx', index=False)\n",
        "\n",
        "# Optionally, get logits from trained data\n",
        "# train_logits = get_logits(model1, train_loader)\n",
        "# Save logits from trained data to a pickle file or DataFrame as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCes3q9LR1S6",
        "outputId": "e5f4c29f-8e15-4b6e-d879-22773b12225c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 79.12%\n"
          ]
        }
      ],
      "source": [
        "model1.eval()\n",
        "total_correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in dev_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        total_correct += (predictions == labels).sum().item()\n",
        "\n",
        "accuracy = total_correct / len(dev_loader.dataset)\n",
        "print(f'Validation Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXFnMO2NPwtf",
        "outputId": "cfac958a-1beb-4ba3-bc81-8003f76904e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from string import punctuation\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DfqEzA1CQ9A"
      },
      "outputs": [],
      "source": [
        "def fil_sent(sent):\n",
        "      \"\"\"\n",
        "      Filter stopwords\n",
        "      \"\"\"\n",
        "\n",
        "      filtered_sentence = ' '.join([w for w in sent.split() if not w in stop_words])\n",
        "      return filtered_sentence\n",
        "\n",
        "def process(sent):\n",
        "      \"\"\"\n",
        "      Apply stemming\n",
        "      \"\"\"\n",
        "\n",
        "      sent = str(sent)\n",
        "      return fil_sent(' '.join([ps.stem(str(x).lower()) for x in word_tokenize(sent)]))\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def extract_style(text):\n",
        "    \"\"\"\n",
        "    Extracting stylometric features of a text\n",
        "    \"\"\"\n",
        "\n",
        "    text = str(text)\n",
        "    len_text = len(text)\n",
        "    len_words = len(text.split())\n",
        "    avg_len = np.mean([len(t) for t in text.split()])\n",
        "    num_short_w = len([t for t in text.split() if len(t) < 3])\n",
        "    per_digit = sum(t.isdigit() for t in text)/len(text)\n",
        "    per_cap = sum(1 for t in text if t.isupper())/len(text)\n",
        "    f_a = sum(1 for t in text if t.lower() == \"a\")/len(text)\n",
        "    f_b = sum(1 for t in text if t.lower() == \"b\")/len(text)\n",
        "    f_c = sum(1 for t in text if t.lower() == \"c\")/len(text)\n",
        "    f_d = sum(1 for t in text if t.lower() == \"d\")/len(text)\n",
        "    f_e = sum(1 for t in text if t.lower() == \"e\")/len(text)\n",
        "    f_f = sum(1 for t in text if t.lower() == \"f\")/len(text)\n",
        "    f_g = sum(1 for t in text if t.lower() == \"g\")/len(text)\n",
        "    f_h = sum(1 for t in text if t.lower() == \"h\")/len(text)\n",
        "    f_i = sum(1 for t in text if t.lower() == \"i\")/len(text)\n",
        "    f_j = sum(1 for t in text if t.lower() == \"j\")/len(text)\n",
        "    f_k = sum(1 for t in text if t.lower() == \"k\")/len(text)\n",
        "    f_l = sum(1 for t in text if t.lower() == \"l\")/len(text)\n",
        "    f_m = sum(1 for t in text if t.lower() == \"m\")/len(text)\n",
        "    f_n = sum(1 for t in text if t.lower() == \"n\")/len(text)\n",
        "    f_o = sum(1 for t in text if t.lower() == \"o\")/len(text)\n",
        "    f_p = sum(1 for t in text if t.lower() == \"p\")/len(text)\n",
        "    f_q = sum(1 for t in text if t.lower() == \"q\")/len(text)\n",
        "    f_r = sum(1 for t in text if t.lower() == \"r\")/len(text)\n",
        "    f_s = sum(1 for t in text if t.lower() == \"s\")/len(text)\n",
        "    f_t = sum(1 for t in text if t.lower() == \"t\")/len(text)\n",
        "    f_u = sum(1 for t in text if t.lower() == \"u\")/len(text)\n",
        "    f_v = sum(1 for t in text if t.lower() == \"v\")/len(text)\n",
        "    f_w = sum(1 for t in text if t.lower() == \"w\")/len(text)\n",
        "    f_x = sum(1 for t in text if t.lower() == \"x\")/len(text)\n",
        "    f_y = sum(1 for t in text if t.lower() == \"y\")/len(text)\n",
        "    f_z = sum(1 for t in text if t.lower() == \"z\")/len(text)\n",
        "    f_1 = sum(1 for t in text if t.lower() == \"1\")/len(text)\n",
        "    f_2 = sum(1 for t in text if t.lower() == \"2\")/len(text)\n",
        "    f_3 = sum(1 for t in text if t.lower() == \"3\")/len(text)\n",
        "    f_4 = sum(1 for t in text if t.lower() == \"4\")/len(text)\n",
        "    f_5 = sum(1 for t in text if t.lower() == \"5\")/len(text)\n",
        "    f_6 = sum(1 for t in text if t.lower() == \"6\")/len(text)\n",
        "    f_7 = sum(1 for t in text if t.lower() == \"7\")/len(text)\n",
        "    f_8 = sum(1 for t in text if t.lower() == \"8\")/len(text)\n",
        "    f_9 = sum(1 for t in text if t.lower() == \"9\")/len(text)\n",
        "    f_0 = sum(1 for t in text if t.lower() == \"0\")/len(text)\n",
        "    f_e_0 = sum(1 for t in text if t.lower() == \"!\")/len(text)\n",
        "    f_e_1 = sum(1 for t in text if t.lower() == \"-\")/len(text)\n",
        "    f_e_2 = sum(1 for t in text if t.lower() == \":\")/len(text)\n",
        "    f_e_3 = sum(1 for t in text if t.lower() == \"?\")/len(text)\n",
        "    f_e_4 = sum(1 for t in text if t.lower() == \".\")/len(text)\n",
        "    f_e_5 = sum(1 for t in text if t.lower() == \",\")/len(text)\n",
        "    f_e_6 = sum(1 for t in text if t.lower() == \";\")/len(text)\n",
        "    f_e_7 = sum(1 for t in text if t.lower() == \"'\")/len(text)\n",
        "    f_e_8 = sum(1 for t in text if t.lower() == \"/\")/len(text)\n",
        "    f_e_9 = sum(1 for t in text if t.lower() == \"(\")/len(text)\n",
        "    f_e_10 = sum(1 for t in text if t.lower() == \")\")/len(text)\n",
        "    f_e_11 = sum(1 for t in text if t.lower() == \"&\")/len(text)\n",
        "    richness = len(list(set(text.split())))/len(text.split())\n",
        "\n",
        "    return pd.Series([avg_len, len_text, len_words, num_short_w, per_digit, per_cap, f_a, f_b, f_c, f_d, f_e, f_f, f_g, f_h, f_i, f_j, f_k, f_l, f_m, f_n, f_o, f_p, f_q, f_r, f_s, f_t, f_u, f_v, f_w, f_x, f_y, f_z, f_0, f_1, f_2, f_3, f_4, f_5, f_6, f_7, f_8, f_9, f_e_0, f_e_1, f_e_2, f_e_3, f_e_4, f_e_5, f_e_6, f_e_7, f_e_8, f_e_9, f_e_10, f_e_11, richness])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVhGE35Mcc9F"
      },
      "outputs": [],
      "source": [
        "test['content_tfidf'] = test['text'].parallel_apply(lambda x: process(x))\n",
        "test[[\"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\",  \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]] = test['text'].parallel_apply(lambda x: extract_style(x))\n",
        "test.to_csv(\"test1.csv\", escapechar='\\\\')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhpkkq3_DbF9"
      },
      "outputs": [],
      "source": [
        "dfbtrain['content_tfidf'] = dfbtrain['text'].parallel_apply(lambda x: process(x))\n",
        "dfbtrain[[\"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\",  \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]] = dfbtrain['text'].parallel_apply(lambda x: extract_style(x))\n",
        "dfbtrain.to_csv(\"dfbtrain_enron.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9rD8_4kxJUl"
      },
      "outputs": [],
      "source": [
        "dfbdev['content_tfidf'] = dfbdev['text'].parallel_apply(lambda x: process(x))\n",
        "dfbdev[[\"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\",  \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]] = dfbdev['text'].parallel_apply(lambda x: extract_style(x))\n",
        "dfbdev.to_csv(\"dfbdev_enron.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "08njNWaS3XJZ",
        "outputId": "0f39c586-15b0-4d15-88f7-4337cfefc096"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/SubtaskB/dfbtrain_enron.csv'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Source and Destination Paths\n",
        "source_file = \"/content/dfbtrain_enron.csv\"  # Change this to your CSV file path\n",
        "destination_folder = \"/content/drive/MyDrive/SubtaskB\"  # Change this to your destination folder path\n",
        "\n",
        "# Copy File\n",
        "shutil.copy(source_file, destination_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGUcci8csoCg"
      },
      "outputs": [],
      "source": [
        "df['content_tfidf'] = df['text'].parallel_apply(lambda x: process(x))\n",
        "df[[\"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\",  \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]] = df['text'].parallel_apply(lambda x: extract_style(x))\n",
        "df.to_csv(\"full_enron.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fdB0_eZRcx8"
      },
      "outputs": [],
      "source": [
        "test['content_tfidf'] = test['text'].parallel_apply(lambda x: process(x))\n",
        "test[[\"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\",  \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]] = test['text'].parallel_apply(lambda x: extract_style(x))\n",
        "test.to_csv(\"test.csv\", escapechar='\\\\')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7xD29JjUj-_"
      },
      "outputs": [],
      "source": [
        "dfdev['content_tfidf'] = dfdev['text'].parallel_apply(lambda x: process(x))\n",
        "dfdev[[\"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\",  \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]] = dfdev['text'].parallel_apply(lambda x: extract_style(x))\n",
        "dfdev.to_csv(\"full_dev.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBT0N3n_Q1-9"
      },
      "outputs": [],
      "source": [
        "dfdev['content_tfidf'] = dfdev['text'].parallel_apply(lambda x: process(x))\n",
        "dfdev[[\"avg_len\", \"len_text\", \"len_words\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\",  \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]] = dfdev['text'].parallel_apply(lambda x: extract_style(x))\n",
        "dfdev.to_csv(\"full_dev.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJs6rUf0fqF2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL1RnK6W4Grd"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/SubtaskA/full_enron.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e827D_bVXibH"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"/content/drive/MyDrive/SubtaskA/full_dev.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MNchOFNQuzG"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(\"/content/drive/MyDrive/SubtaskA/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "tLeciCwxGf4-",
        "outputId": "1b4ffe5e-fd45-460f-c0f5-d914317847ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               text  id  \\\n",
              "0           0  Today, many adults or teenage drivers are hook...   0   \n",
              "1           1  The automobile, since its advent, has revoluti...   1   \n",
              "2           2   One policy that could potentially improve aca...   2   \n",
              "3           3  Title: Navigating the Road Ahead: The Case for...   3   \n",
              "4           4  Have you ever woken up in the morning and wish...   4   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  Today many adults or teenage drivers are hooke...   \n",
              "1  The automobile since its advent has revolution...   \n",
              "2  One policy that could potentially improve acad...   \n",
              "3  Title Navigating the Road Ahead The Case for D...   \n",
              "4  Have you ever woken up in the morning and wish...   \n",
              "\n",
              "                                       content_tfidf   avg_len  len_text  \\\n",
              "0  today , mani adult teenag driver hook onto pho...  4.482759    2715.0   \n",
              "1  automobil , sinc advent , ha revolution way hu...  5.945813    2825.0   \n",
              "2  one polici could potenti improv academ perform...  5.943470    3578.0   \n",
              "3  titl : navig road ahead : case driverless car ...  6.262626    2880.0   \n",
              "4  ever woken morn wish could stay bed ? mani stu...  5.144181    5982.0   \n",
              "\n",
              "   len_words  num_short_w  per_digit  ...     f_e_3     f_e_4     f_e_5  \\\n",
              "0      493.0         99.0   0.002947  ...  0.000000  0.011418  0.006262   \n",
              "1      406.0         64.0   0.000708  ...  0.000000  0.008142  0.010973   \n",
              "2      513.0         99.0   0.000000  ...  0.000279  0.004751  0.005031   \n",
              "3      396.0         72.0   0.000000  ...  0.000000  0.005556  0.007292   \n",
              "4      971.0        174.0   0.000000  ...  0.000167  0.008358  0.008860   \n",
              "\n",
              "      f_e_6     f_e_7  f_e_8  f_e_9  f_e_10  f_e_11  richness  \n",
              "0  0.000000  0.000368    0.0    0.0     0.0     0.0  0.541582  \n",
              "1  0.000000  0.001416    0.0    0.0     0.0     0.0  0.667488  \n",
              "2  0.000000  0.000279    0.0    0.0     0.0     0.0  0.493177  \n",
              "3  0.000694  0.000347    0.0    0.0     0.0     0.0  0.669192  \n",
              "4  0.000167  0.000669    0.0    0.0     0.0     0.0  0.390319  \n",
              "\n",
              "[5 rows x 60 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-269b759e-556f-4cd9-abda-f81004b6a277\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>content_tfidf</th>\n",
              "      <th>avg_len</th>\n",
              "      <th>len_text</th>\n",
              "      <th>len_words</th>\n",
              "      <th>num_short_w</th>\n",
              "      <th>per_digit</th>\n",
              "      <th>...</th>\n",
              "      <th>f_e_3</th>\n",
              "      <th>f_e_4</th>\n",
              "      <th>f_e_5</th>\n",
              "      <th>f_e_6</th>\n",
              "      <th>f_e_7</th>\n",
              "      <th>f_e_8</th>\n",
              "      <th>f_e_9</th>\n",
              "      <th>f_e_10</th>\n",
              "      <th>f_e_11</th>\n",
              "      <th>richness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Today, many adults or teenage drivers are hook...</td>\n",
              "      <td>0</td>\n",
              "      <td>Today many adults or teenage drivers are hooke...</td>\n",
              "      <td>today , mani adult teenag driver hook onto pho...</td>\n",
              "      <td>4.482759</td>\n",
              "      <td>2715.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.002947</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011418</td>\n",
              "      <td>0.006262</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.541582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The automobile, since its advent, has revoluti...</td>\n",
              "      <td>1</td>\n",
              "      <td>The automobile since its advent has revolution...</td>\n",
              "      <td>automobil , sinc advent , ha revolution way hu...</td>\n",
              "      <td>5.945813</td>\n",
              "      <td>2825.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>0.010973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.667488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>One policy that could potentially improve aca...</td>\n",
              "      <td>2</td>\n",
              "      <td>One policy that could potentially improve acad...</td>\n",
              "      <td>one polici could potenti improv academ perform...</td>\n",
              "      <td>5.943470</td>\n",
              "      <td>3578.0</td>\n",
              "      <td>513.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.004751</td>\n",
              "      <td>0.005031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.493177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Title: Navigating the Road Ahead: The Case for...</td>\n",
              "      <td>3</td>\n",
              "      <td>Title Navigating the Road Ahead The Case for D...</td>\n",
              "      <td>titl : navig road ahead : case driverless car ...</td>\n",
              "      <td>6.262626</td>\n",
              "      <td>2880.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005556</td>\n",
              "      <td>0.007292</td>\n",
              "      <td>0.000694</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.669192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Have you ever woken up in the morning and wish...</td>\n",
              "      <td>4</td>\n",
              "      <td>Have you ever woken up in the morning and wish...</td>\n",
              "      <td>ever woken morn wish could stay bed ? mani stu...</td>\n",
              "      <td>5.144181</td>\n",
              "      <td>5982.0</td>\n",
              "      <td>971.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.008358</td>\n",
              "      <td>0.008860</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.000669</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.390319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 60 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-269b759e-556f-4cd9-abda-f81004b6a277')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-269b759e-556f-4cd9-abda-f81004b6a277 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-269b759e-556f-4cd9-abda-f81004b6a277');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e6206543-42f0-4077-b1e5-16f5affb22e0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6206543-42f0-4077-b1e5-16f5affb22e0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e6206543-42f0-4077-b1e5-16f5affb22e0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_json('/content/drive/MyDrive/SubtaskA/subtaskA_monolingual.jsonl', lines=True)"
      ],
      "metadata": {
        "id": "4sUY271WRjLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ZsgWqwnaGkAm",
        "outputId": "2cbee0ce-25aa-42e6-bfe7-145e70f9958d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  label     id\n",
              "0      Today, many adults or teenage drivers are hook...      0      0\n",
              "1      The automobile, since its advent, has revoluti...      1      1\n",
              "2       One policy that could potentially improve aca...      1      2\n",
              "3      Title: Navigating the Road Ahead: The Case for...      1      3\n",
              "4      Have you ever woken up in the morning and wish...      0      4\n",
              "...                                                  ...    ...    ...\n",
              "34267  There are many advantages of limiting car usag...      0  34267\n",
              "34268  When discussing the merits of the electoral co...      1  34268\n",
              "34269  In favor of student-designed summer assignment...      1  34269\n",
              "34270  No, FACE is not created by aliens. as a person...      0  34270\n",
              "34271   Distance learning has become a widely accepte...      1  34271\n",
              "\n",
              "[34272 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98b68c0d-8b89-4b14-b765-505f9b9de15d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Today, many adults or teenage drivers are hook...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The automobile, since its advent, has revoluti...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One policy that could potentially improve aca...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Title: Navigating the Road Ahead: The Case for...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have you ever woken up in the morning and wish...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34267</th>\n",
              "      <td>There are many advantages of limiting car usag...</td>\n",
              "      <td>0</td>\n",
              "      <td>34267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34268</th>\n",
              "      <td>When discussing the merits of the electoral co...</td>\n",
              "      <td>1</td>\n",
              "      <td>34268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34269</th>\n",
              "      <td>In favor of student-designed summer assignment...</td>\n",
              "      <td>1</td>\n",
              "      <td>34269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34270</th>\n",
              "      <td>No, FACE is not created by aliens. as a person...</td>\n",
              "      <td>0</td>\n",
              "      <td>34270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34271</th>\n",
              "      <td>Distance learning has become a widely accepte...</td>\n",
              "      <td>1</td>\n",
              "      <td>34271</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34272 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98b68c0d-8b89-4b14-b765-505f9b9de15d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98b68c0d-8b89-4b14-b765-505f9b9de15d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98b68c0d-8b89-4b14-b765-505f9b9de15d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97465806-0a65-4077-a9c7-97a810e80041\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97465806-0a65-4077-a9c7-97a810e80041')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97465806-0a65-4077-a9c7-97a810e80041 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f54eed49-2bb6-498d-a35b-6973ad003516\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test_labels')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f54eed49-2bb6-498d-a35b-6973ad003516 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test_labels');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_labels",
              "summary": "{\n  \"name\": \"df_test_labels\",\n  \"rows\": 34272,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31200,\n        \"samples\": [\n          \"I think using this technology in a classroom would be a huge breakthrough.  Teachers wouldn't have to work as hard to figure out what he or she needs to do to help a student learn what they need to learn. This technology can tell what their emotional state is when in the classroom. If they are bored they might not like the way their teacher is teaching them. So the teacher can modify the way she teaches that specific lesson, so that the student has a better attitude toward that subject.\\n This technology can also help councelers talk to the students that might be having personal problems like bullies, or family issues at home. Kids wouldn't be able to hide their emotions as well with this techlology being in every classrom. For example with a false smile the mouth is stretched sideways using the zygomatic major, and another muscle called the risorius. You cant download the software on a normal computer, so schools would have to pay for the device its-self. It would be extremely expensive but it would help many students in classrooms, or some that need counceling.  Humans perform this type of calculation every day, for instance when you ask a friend if they are ok, because they look depressed or angry. We can perform this calculation as accurately as the current technology we have now.  For example Leonardo da Vinci used this type of calculation and knew exactly how her face needed to look in order to get the emotions he was looking for. \\nIn conclusion this technology has many benefits for students and children that need counceling for personal problems, and or family problems at home. \",\n          \" The use of cell phones while driving is a dangerous and potentially deadly habit that has become all too common in the American public. Despite the known risks and consequences, many people continue to engage in this distracting behavior, putting themselves and others on the road at risk of accident and injury.\\n\\nRecent studies have shown that cell phone use while driving is a major contributing factor to distracted driving, which is responsible for thousands of accidents and hundreds of deaths each year. In fact, according to the National Highway Traffic Safety Administration (NHTSA), distracted driving claimed the lives of 3,142 people in 2019 alone.\\n\\nThere are several ways in which cell phone use can distract a driver and increase the risk of an accident. One of the most common is known as visual distraction, which occurs when a driver takes their eyes off the road to look at their phone. This can happen when reading a text message, checking a notification, or even just looking at the phone screen to see who is calling. Another type of distraction is manual distraction, which happens when a driver takes their hands off the wheel to handle their phone, such as when texting or dialing a number. Finally, cognitive distraction occurs when a driver's attention is focused on their phone instead of the road, even if their eyes are on the wheel and their hands are on the wheel. A driver who is distracted by their cell phone may not be aware of upcoming stops, changing traffic patterns, or other hazards on the road.\\n\\nIn addition to the dangers of distracted driving, cell phone use while driving can also lead to other reckless behaviors. For example, a driver who is distracted by their phone may fail to notice that they are going over the speed limit or fail to stop at a red light. This can result in costly penalties and consequences for the driver, including fines, citations, and increased insurance rates. In some cases, distracted driving may even result in criminal charges, especially if it leads to injury or death.\\n\\nTo combat the dangers of cell phone use while driving, many states have implemented laws to restrict their use behind the wheel. For example, some states have banned handheld cell phone use while driving, requiring drivers to use hands-free devices if they need to make a call or send a message. Others have banned texting while driving altogether, regardless of whether the driver is using a hands-free device. These laws are designed to increase public safety and reduce the number of accidents and injuries caused by distracted driving. \\n\\nDespite these laws and the known risks of cell phone use while driving, many people continue to engage in this dangerous behavior. To reduce cell phone use while driving and increase public safety, it is important to increase awareness of the risks and consequences of distracted driving. This can be done through educational campaigns, reminders of the legal penalties for distracted driving, and advocating for further legislation to restrict cell phone use behind the wheel. By taking these steps, we can work towards making the roads safer for everyone and preventing accidents and injuries caused by distracted driving. \\n\\nIn conclusion, cell phone use while driving is a dangerous and potentially deadly habit that puts the safety of the American public at risk. By increasing awareness of the dangers of distracted driving and implementing laws to restrict cell phone use behind the wheel, we can work towards reducing accidents and injuries caused by this behavior. Ultimately, the responsibility lies with each individual driver to prioritize safety and avoid any distractions while operating a vehicle. \\n\\nWould you like help with another problem statement? \",\n          \"Have you ever just wondered if there could be life somewhere else from earth?\\n\\nIf so then how about the face that they found on mars. Many people dont agree that it's just landform that built it's self up and just happened to resembul a face. Others would disagree and say that it is just land and that shodows were the main purpose of the enitre thing that made it look like a face. Why did the face on mars not look the same in 1976 i looked like a smilly face at first.  When the picuture was taken it was taken in many different angles. That shows that there is a posability that the picture that they took at the time was in a way that made it have shadows an some sides.  The camara that took it could have been faceing in the direction that the sun was shining and got some of the light make shadows on the landform.\\n\\nThe scientist that looked at the picture taken by Viking 1 says it was only landform shaped in different ways. Makeing it appear like something that is not really there. Garvin says that it remindes him of a lava dome around the America West it's about the same height as the face that they found on mars.  When they first took a picture of the face in 1976 it looked nothing like a face it only looked like a smily face and even that was hard to tell. After a couple of years in 1998 in looked like an oval shaped box and it was sunken in. And in 2001 is when started to shape into something over the years in changed and over more years it will change even more.  After that and so on because that's just what landforms do they change but, you can't always see the same thing you sole once. \\n I can see why some people don't see why it could be a landform And that its actually something else it does look like a face .it could actually be a statue and not just land shaped in to something but the thing is of it was really a statue or remaines of something or someone  But,then why wouldn't it looks fuler or have actuale face there would be bones. And if there was a statues then why is it only it's head you would a lest find the other parts of the statue but we haven't and that's because it only a land form shaped into something almost everyone beleives to be actuale life.  that object that was found on mars is only land built up that looks some what like a face and not a statue or remains of a living person or creature. but something that was a different landform a long time ago before it became what is know as the face on mars. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9893,\n        \"min\": 0,\n        \"max\": 34271,\n        \"num_unique_values\": 34272,\n        \"samples\": [\n          6194,\n          16004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.concat([test.set_index('id'), df_test_labels.set_index('id')], axis=1, join='inner').reset_index()"
      ],
      "metadata": {
        "id": "R8oVwhiURspz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test= test.set_index('id').drop(columns=['Unnamed: 0'])"
      ],
      "metadata": {
        "id": "ig6nYppGYDmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "H9cmUOQ8Ppj9",
        "outputId": "1301ccaa-195e-4ac4-fe9a-6825bc566a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text  \\\n",
              "id                                                      \n",
              "0   Today, many adults or teenage drivers are hook...   \n",
              "1   The automobile, since its advent, has revoluti...   \n",
              "2    One policy that could potentially improve aca...   \n",
              "3   Title: Navigating the Road Ahead: The Case for...   \n",
              "4   Have you ever woken up in the morning and wish...   \n",
              "\n",
              "                                         cleaned_text  \\\n",
              "id                                                      \n",
              "0   Today many adults or teenage drivers are hooke...   \n",
              "1   The automobile since its advent has revolution...   \n",
              "2   One policy that could potentially improve acad...   \n",
              "3   Title Navigating the Road Ahead The Case for D...   \n",
              "4   Have you ever woken up in the morning and wish...   \n",
              "\n",
              "                                        content_tfidf   avg_len  len_text  \\\n",
              "id                                                                          \n",
              "0   today , mani adult teenag driver hook onto pho...  4.482759    2715.0   \n",
              "1   automobil , sinc advent , ha revolution way hu...  5.945813    2825.0   \n",
              "2   one polici could potenti improv academ perform...  5.943470    3578.0   \n",
              "3   titl : navig road ahead : case driverless car ...  6.262626    2880.0   \n",
              "4   ever woken morn wish could stay bed ? mani stu...  5.144181    5982.0   \n",
              "\n",
              "    len_words  num_short_w  per_digit   per_cap       f_a  ...     f_e_5  \\\n",
              "id                                                         ...             \n",
              "0       493.0         99.0   0.002947  0.012155  0.060773  ...  0.006262   \n",
              "1       406.0         64.0   0.000708  0.009558  0.065487  ...  0.010973   \n",
              "2       513.0         99.0   0.000000  0.007826  0.071828  ...  0.005031   \n",
              "3       396.0         72.0   0.000000  0.009722  0.071875  ...  0.007292   \n",
              "4       971.0        174.0   0.000000  0.009696  0.059679  ...  0.008860   \n",
              "\n",
              "       f_e_6     f_e_7  f_e_8  f_e_9  f_e_10  f_e_11  richness  \\\n",
              "id                                                               \n",
              "0   0.000000  0.000368    0.0    0.0     0.0     0.0  0.541582   \n",
              "1   0.000000  0.001416    0.0    0.0     0.0     0.0  0.667488   \n",
              "2   0.000000  0.000279    0.0    0.0     0.0     0.0  0.493177   \n",
              "3   0.000694  0.000347    0.0    0.0     0.0     0.0  0.669192   \n",
              "4   0.000167  0.000669    0.0    0.0     0.0     0.0  0.390319   \n",
              "\n",
              "                                                 text  label  \n",
              "id                                                            \n",
              "0   Today, many adults or teenage drivers are hook...      0  \n",
              "1   The automobile, since its advent, has revoluti...      1  \n",
              "2    One policy that could potentially improve aca...      1  \n",
              "3   Title: Navigating the Road Ahead: The Case for...      1  \n",
              "4   Have you ever woken up in the morning and wish...      0  \n",
              "\n",
              "[5 rows x 60 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4433ebf7-8112-44dc-8446-5faa0b12c61a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>content_tfidf</th>\n",
              "      <th>avg_len</th>\n",
              "      <th>len_text</th>\n",
              "      <th>len_words</th>\n",
              "      <th>num_short_w</th>\n",
              "      <th>per_digit</th>\n",
              "      <th>per_cap</th>\n",
              "      <th>f_a</th>\n",
              "      <th>...</th>\n",
              "      <th>f_e_5</th>\n",
              "      <th>f_e_6</th>\n",
              "      <th>f_e_7</th>\n",
              "      <th>f_e_8</th>\n",
              "      <th>f_e_9</th>\n",
              "      <th>f_e_10</th>\n",
              "      <th>f_e_11</th>\n",
              "      <th>richness</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Today, many adults or teenage drivers are hook...</td>\n",
              "      <td>Today many adults or teenage drivers are hooke...</td>\n",
              "      <td>today , mani adult teenag driver hook onto pho...</td>\n",
              "      <td>4.482759</td>\n",
              "      <td>2715.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.002947</td>\n",
              "      <td>0.012155</td>\n",
              "      <td>0.060773</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006262</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.541582</td>\n",
              "      <td>Today, many adults or teenage drivers are hook...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The automobile, since its advent, has revoluti...</td>\n",
              "      <td>The automobile since its advent has revolution...</td>\n",
              "      <td>automobil , sinc advent , ha revolution way hu...</td>\n",
              "      <td>5.945813</td>\n",
              "      <td>2825.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.000708</td>\n",
              "      <td>0.009558</td>\n",
              "      <td>0.065487</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.667488</td>\n",
              "      <td>The automobile, since its advent, has revoluti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One policy that could potentially improve aca...</td>\n",
              "      <td>One policy that could potentially improve acad...</td>\n",
              "      <td>one polici could potenti improv academ perform...</td>\n",
              "      <td>5.943470</td>\n",
              "      <td>3578.0</td>\n",
              "      <td>513.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>0.071828</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.493177</td>\n",
              "      <td>One policy that could potentially improve aca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Title: Navigating the Road Ahead: The Case for...</td>\n",
              "      <td>Title Navigating the Road Ahead The Case for D...</td>\n",
              "      <td>titl : navig road ahead : case driverless car ...</td>\n",
              "      <td>6.262626</td>\n",
              "      <td>2880.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009722</td>\n",
              "      <td>0.071875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007292</td>\n",
              "      <td>0.000694</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.669192</td>\n",
              "      <td>Title: Navigating the Road Ahead: The Case for...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have you ever woken up in the morning and wish...</td>\n",
              "      <td>Have you ever woken up in the morning and wish...</td>\n",
              "      <td>ever woken morn wish could stay bed ? mani stu...</td>\n",
              "      <td>5.144181</td>\n",
              "      <td>5982.0</td>\n",
              "      <td>971.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009696</td>\n",
              "      <td>0.059679</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008860</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.000669</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.390319</td>\n",
              "      <td>Have you ever woken up in the morning and wish...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 60 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4433ebf7-8112-44dc-8446-5faa0b12c61a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4433ebf7-8112-44dc-8446-5faa0b12c61a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4433ebf7-8112-44dc-8446-5faa0b12c61a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-42e788b2-2f56-4743-b4ae-e3cf5e44d016\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42e788b2-2f56-4743-b4ae-e3cf5e44d016')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-42e788b2-2f56-4743-b4ae-e3cf5e44d016 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "OeBCyHA9lQt9",
        "outputId": "d3fe4297-2081-4c38-a36b-5e5430462fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               text  label  \\\n",
              "0           0  Forza Motorsport is a popular racing game that...      1   \n",
              "1           1  Buying Virtual Console games for your Nintendo...      1   \n",
              "2           2  Windows NT 4.0 was a popular operating system ...      1   \n",
              "3           3  How to Make Perfume\\n\\nPerfume is a great way ...      1   \n",
              "4           4  How to Convert Song Lyrics to a Song'\\n\\nConve...      1   \n",
              "\n",
              "     model   source  id                                      content_tfidf  \\\n",
              "0  chatGPT  wikihow   0  forza motorsport popular race game provid play...   \n",
              "1  chatGPT  wikihow   1  buy virtual consol game nintendo wii fun easi ...   \n",
              "2  chatGPT  wikihow   2  window nt 4.0 wa popular oper system back day ...   \n",
              "3  chatGPT  wikihow   3  make perfum perfum great way enhanc person sce...   \n",
              "4  chatGPT  wikihow   4  convert song lyric song' convert song lyric fu...   \n",
              "\n",
              "    avg_len  len_text  len_words  ...     f_e_3     f_e_4     f_e_5  f_e_6  \\\n",
              "0  4.457002    2244.0      407.0  ...  0.000000  0.015152  0.014706    0.0   \n",
              "1  4.418502    3728.0      681.0  ...  0.000000  0.017972  0.006706    0.0   \n",
              "2  4.709748    5237.0      913.0  ...  0.000000  0.020432  0.005728    0.0   \n",
              "3  4.772277    4729.0      808.0  ...  0.000000  0.014168  0.005709    0.0   \n",
              "4  4.407733    3095.0      569.0  ...  0.000646  0.012601  0.008401    0.0   \n",
              "\n",
              "      f_e_7     f_e_8     f_e_9    f_e_10  f_e_11  richness  \n",
              "0  0.000891  0.000000  0.000000  0.000000     0.0  0.577396  \n",
              "1  0.003219  0.000000  0.000000  0.000000     0.0  0.427313  \n",
              "2  0.001146  0.000382  0.000191  0.000191     0.0  0.346112  \n",
              "3  0.001269  0.000000  0.002326  0.002326     0.0  0.407178  \n",
              "4  0.003877  0.000000  0.000646  0.000646     0.0  0.427065  \n",
              "\n",
              "[5 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b909ad79-eabd-4866-8e80-c1bef34a0364\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>model</th>\n",
              "      <th>source</th>\n",
              "      <th>id</th>\n",
              "      <th>content_tfidf</th>\n",
              "      <th>avg_len</th>\n",
              "      <th>len_text</th>\n",
              "      <th>len_words</th>\n",
              "      <th>...</th>\n",
              "      <th>f_e_3</th>\n",
              "      <th>f_e_4</th>\n",
              "      <th>f_e_5</th>\n",
              "      <th>f_e_6</th>\n",
              "      <th>f_e_7</th>\n",
              "      <th>f_e_8</th>\n",
              "      <th>f_e_9</th>\n",
              "      <th>f_e_10</th>\n",
              "      <th>f_e_11</th>\n",
              "      <th>richness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Forza Motorsport is a popular racing game that...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>0</td>\n",
              "      <td>forza motorsport popular race game provid play...</td>\n",
              "      <td>4.457002</td>\n",
              "      <td>2244.0</td>\n",
              "      <td>407.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015152</td>\n",
              "      <td>0.014706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.577396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Buying Virtual Console games for your Nintendo...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>1</td>\n",
              "      <td>buy virtual consol game nintendo wii fun easi ...</td>\n",
              "      <td>4.418502</td>\n",
              "      <td>3728.0</td>\n",
              "      <td>681.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017972</td>\n",
              "      <td>0.006706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003219</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.427313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Windows NT 4.0 was a popular operating system ...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>2</td>\n",
              "      <td>window nt 4.0 wa popular oper system back day ...</td>\n",
              "      <td>4.709748</td>\n",
              "      <td>5237.0</td>\n",
              "      <td>913.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020432</td>\n",
              "      <td>0.005728</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001146</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.346112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>How to Make Perfume\\n\\nPerfume is a great way ...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>3</td>\n",
              "      <td>make perfum perfum great way enhanc person sce...</td>\n",
              "      <td>4.772277</td>\n",
              "      <td>4729.0</td>\n",
              "      <td>808.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014168</td>\n",
              "      <td>0.005709</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002326</td>\n",
              "      <td>0.002326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.407178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>How to Convert Song Lyrics to a Song'\\n\\nConve...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>4</td>\n",
              "      <td>convert song lyric song' convert song lyric fu...</td>\n",
              "      <td>4.407733</td>\n",
              "      <td>3095.0</td>\n",
              "      <td>569.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.012601</td>\n",
              "      <td>0.008401</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.427065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 62 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b909ad79-eabd-4866-8e80-c1bef34a0364')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b909ad79-eabd-4866-8e80-c1bef34a0364 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b909ad79-eabd-4866-8e80-c1bef34a0364');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-791aee79-5ed2-4204-b235-476ae7a1c6b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-791aee79-5ed2-4204-b235-476ae7a1c6b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-791aee79-5ed2-4204-b235-476ae7a1c6b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj8iUriJ4cqh",
        "outputId": "860212ce-73ac-4b57-8efc-c4b392b0563f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "119757"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8yuBc6PE7S4",
        "outputId": "e98b2e47-6dab-4266-8e03-d2faf740f9a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "34272"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmqn53Znn8Wa"
      },
      "outputs": [],
      "source": [
        "df['content_tfidf'].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH4Qv0_g4gQk",
        "outputId": "7ff17611-795f-41c6-fb68-f23e80bf0f0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "119757"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApmH9ZES4iGe",
        "outputId": "cdba25b6-7f5c-4bc2-89a7-63306376cdba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Unnamed: 0                                               text  label  \\\n",
            "119752      119752  The paper is an interesting contribution, prim...      0   \n",
            "119753      119753  \\nWe thank the reviewers for all their comment...      0   \n",
            "119754      119754  The authors introduce a semi-supervised method...      0   \n",
            "119755      119755  This paper proposes the Neural Graph Machine t...      0   \n",
            "119756      119756  The paper proposes a model that aims at learni...      0   \n",
            "\n",
            "        model    source      id  \\\n",
            "119752  human  peerread  119752   \n",
            "119753  human  peerread  119753   \n",
            "119754  human  peerread  119754   \n",
            "119755  human  peerread  119755   \n",
            "119756  human  peerread  119756   \n",
            "\n",
            "                                            content_tfidf   avg_len  len_text  \\\n",
            "119752  paper interest contribut , primarili gener wes...  5.391304     440.0   \n",
            "119753  thank review comment . howev would like respon...  5.459754    4837.0   \n",
            "119754  author introduc semi-supervis method neural ne...  5.320000    1109.0   \n",
            "119755  thi paper propos neural graph machin add graph...  4.801980    1176.0   \n",
            "119756  paper propos model aim learn label node graph ...  5.162791    1065.0   \n",
            "\n",
            "        len_words  ...  f_e_3     f_e_4     f_e_5     f_e_6     f_e_7  \\\n",
            "119752       69.0  ...    0.0  0.009091  0.009091  0.000000  0.006818   \n",
            "119753      733.0  ...    0.0  0.013231  0.012818  0.000413  0.000000   \n",
            "119754      175.0  ...    0.0  0.008115  0.010821  0.000902  0.000000   \n",
            "119755      202.0  ...    0.0  0.011905  0.008503  0.000000  0.000000   \n",
            "119756      172.0  ...    0.0  0.012207  0.003756  0.000000  0.003756   \n",
            "\n",
            "           f_e_8     f_e_9    f_e_10   f_e_11  richness  \n",
            "119752  0.000000  0.000000  0.004545  0.00000  0.840580  \n",
            "119753  0.000413  0.003928  0.003928  0.00062  0.547067  \n",
            "119754  0.000000  0.006312  0.006312  0.00000  0.651429  \n",
            "119755  0.000000  0.000000  0.000000  0.00000  0.643564  \n",
            "119756  0.000000  0.001878  0.001878  0.00000  0.662791  \n",
            "\n",
            "[5 rows x 62 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df1.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXRxwSBPHgD2"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/SubtaskB/dfbtrain_enron.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnbSH-WHHh3X"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"/content/drive/MyDrive/SubtaskB/dfbdev_enron.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly2MiA6ibRKw"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3_xKc1PHz22",
        "outputId": "79b5f2a4-cb14-468e-d600-6d4fb04a7f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#####\n",
            "Training style classifier\n",
            "Training done, accuracy is :  0.38766666666666666\n",
            "Training done, f1-score is :  0.37211217875129776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "\n",
        "print(\"#####\")\n",
        "print(\"Training style classifier\")\n",
        "# Ensure that the subtaskA folder exists in your Google Drive\n",
        "# Specify the path to your drive folder\n",
        "drive_folder = '/content/drive/MyDrive/'\n",
        "\n",
        "subtaskA_folder = os.path.join(drive_folder, 'SubtaskB')\n",
        "\n",
        "X_style_train = df1[[\"avg_len\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]]\n",
        "X_style_test = df2[[\"avg_len\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]]\n",
        "\n",
        "#clf = xgb.XGBClassifier().fit(X_style_train, nlp_train['Target'])\n",
        "#clf = LogisticRegression(random_state=0).fit(X_style_train, df1['label'])\n",
        "clf = LogisticRegression(random_state=0, multi_class='auto', max_iter=1000).fit(X_style_train, df1['label'])\n",
        "\n",
        "y_pred = clf.predict(X_style_test)\n",
        "y_proba1 = clf.predict_proba(X_style_test)\n",
        "y_proba_train1 = clf.predict_proba(X_style_train)\n",
        "score_style = accuracy_score(df2['label'], y_pred)\n",
        "f1_style = f1_score(df2['label'], y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_style)\n",
        "print(\"Training done, f1-score is : \", f1_style)\n",
        "\n",
        "# Save predicted probabilities for test set in the subtaskA folder in your Google Drive\n",
        "with open(os.path.join(subtaskA_folder, 'dev_set_probabilities1.pkl'), 'wb') as f:\n",
        "    pickle.dump(y_proba1, f)\n",
        "\n",
        "# Save predicted probabilities for training set in the subtaskA folder in your Google Drive\n",
        "with open(os.path.join(subtaskA_folder, 'training_set_probabilities1.pkl'), 'wb') as f:\n",
        "    pickle.dump(y_proba_train1, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp_6LhReE6a1",
        "outputId": "5e35ed27-32fa-40b2-ce6b-c0bd830fdd2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#####\n",
            "Training style classifier\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import os\n",
        "\n",
        "print(\"#####\")\n",
        "print(\"Training style classifier\")\n",
        "# Ensure that the subtaskA folder exists in your Google Drive\n",
        "# Specify the path to your drive folder\n",
        "drive_folder = '/content/drive/MyDrive/'\n",
        "\n",
        "subtaskA_folder = os.path.join(drive_folder, 'SubtaskA')\n",
        "\n",
        "X_style_train = df1[[\"avg_len\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]]\n",
        "X_style_test = test[[\"avg_len\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]]\n",
        "\n",
        "#clf = xgb.XGBClassifier().fit(X_style_train, nlp_train['Target'])\n",
        "clf = LogisticRegression(random_state=0).fit(X_style_train, df1['label'])\n",
        "y_pred = clf.predict(X_style_test)\n",
        "y_proba1 = clf.predict_proba(X_style_test)\n",
        "y_proba_train1 = clf.predict_proba(X_style_train)\n",
        "# score_style = accuracy_score(test['label'], y_pred)\n",
        "# f1_style = f1_score(test['label'], y_pred, average=\"macro\")\n",
        "\n",
        "# print(\"Training done, accuracy is : \", score_style)\n",
        "# print(\"Training done, f1-score is : \", f1_style)\n",
        "\n",
        "# Save predicted probabilities for test set in the subtaskA folder in your Google Drive\n",
        "with open(os.path.join(subtaskA_folder, 'test_set_probabilities1.pkl'), 'wb') as f:\n",
        "    pickle.dump(y_proba1, f)\n",
        "\n",
        "# Save predicted probabilities for training set in the subtaskA folder in your Google Drive\n",
        "with open(os.path.join(subtaskA_folder, 'training_set_probabilities1.pkl'), 'wb') as f:\n",
        "    pickle.dump(y_proba_train1, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "546Ouj9b9sNh",
        "outputId": "8518a0f5-9ea1-43b9-a075-bb2fadfa7a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#####\n",
            "Training style classifier\n",
            "Training done, accuracy is :  0.4006\n",
            "Training done, f1-score is :  0.29137648450951836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "#  # Style-based classifier\n",
        "\n",
        "# print(\"#####\")\n",
        "# print(\"Training style classifier\")\n",
        "\n",
        "# X_style_train = df1[[\"avg_len\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]]\n",
        "# X_style_test = df2[[\"avg_len\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]]\n",
        "\n",
        "# #clf = xgb.XGBClassifier().fit(X_style_train, nlp_train['Target'])\n",
        "# clf = LogisticRegression(random_state=0).fit(X_style_train, df1['label'])\n",
        "# y_pred = clf.predict(X_style_test)\n",
        "# y_proba = clf.predict_proba(X_style_test)\n",
        "# y_proba_train = clf.predict_proba(X_style_train)\n",
        "# score_style = accuracy_score(df2['label'], y_pred)\n",
        "# f1_style = f1_score(df2['label'], y_pred, average=\"macro\")\n",
        "\n",
        "# print(\"Training done, accuracy is : \", score_style)\n",
        "# print(\"Training done, f1-score is : \", f1_style)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "print(\"#####\")\n",
        "print(\"Training style classifier\")\n",
        "\n",
        "X_style_train = df1[[\"avg_len\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]]\n",
        "X_style_test = test[[\"avg_len\", \"num_short_w\", \"per_digit\", \"per_cap\", \"f_a\", \"f_b\", \"f_c\", \"f_d\", \"f_e\", \"f_f\", \"f_g\", \"f_h\", \"f_i\", \"f_j\", \"f_k\", \"f_l\", \"f_m\", \"f_n\", \"f_o\", \"f_p\", \"f_q\", \"f_r\", \"f_s\", \"f_t\", \"f_u\", \"f_v\", \"f_w\", \"f_x\", \"f_y\", \"f_z\", \"f_0\", \"f_1\", \"f_2\", \"f_3\", \"f_4\", \"f_5\", \"f_6\", \"f_7\", \"f_8\", \"f_9\", \"f_e_0\", \"f_e_1\", \"f_e_2\", \"f_e_3\", \"f_e_4\", \"f_e_5\", \"f_e_6\", \"f_e_7\", \"f_e_8\", \"f_e_9\", \"f_e_10\", \"f_e_11\", \"richness\"]]\n",
        "\n",
        "#clf = xgb.XGBClassifier().fit(X_style_train, nlp_train['Target'])\n",
        "clf = LogisticRegression(random_state=0).fit(X_style_train, df1['label'])\n",
        "y_pred = clf.predict(X_style_test)\n",
        "y_proba = clf.predict_proba(X_style_test)\n",
        "y_proba_train = clf.predict_proba(X_style_train)\n",
        "score_style = accuracy_score(test['label'], y_pred)\n",
        "f1_style = f1_score(test['label'], y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_style)\n",
        "print(\"Training done, f1-score is : \", f1_style)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "monfMeLJO_Ux",
        "outputId": "fc1dcd29-d38a-4a69-9ef0-dc5fa3cb799f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#####\n",
            "Training style classifier\n",
            "Training done, accuracy is :  0.4922385620915033\n",
            "Training done, f1-score is :  0.47849322811516626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk8M7HxGb-_Z",
        "outputId": "9ab6bab8-d251-46cc-bbc6-142e823a9098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0         1\n",
            "1         1\n",
            "2         1\n",
            "3         1\n",
            "4         1\n",
            "         ..\n",
            "119752    0\n",
            "119753    0\n",
            "119754    0\n",
            "119755    0\n",
            "119756    0\n",
            "Name: label, Length: 119757, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df1['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms9R48U_cMjX",
        "outputId": "95a86b92-bfc6-4c6d-f56a-c7ed3a2723a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "119757"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fYVIc3PcPaD",
        "outputId": "9628e220-4515-47fb-bdc3-94054964142e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0BgFoCAnAvL",
        "outputId": "27d45c9c-e5f8-45d6-c20a-83fc619d4ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forza motorsport popular race game provid player abil race variou track differ vehicl . whether 're season racer newbi , play forza motorsport fun experi . thi articl , take differ step play forza motorsport . step 1 . insert game disc first step insert game disc consol comput . follow instruct set game . step 2 . choos game onc game set , choos game 'd like play . forza motorsport ha differ mode : career , free play , arcad . thi articl , focu arcad mode . step 3 . make quick race arcad mode on\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7vOw9CnnE3i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fWqLjuOig-B",
        "outputId": "d4aa0bf3-89dc-4f28-ab2f-32cc9c2b2ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"forza motorsport popular race game provid player abil race variou track differ vehicl . whether 're season racer newbi , play forza motorsport fun experi . thi articl , take differ step play forza motorsport . step 1 . insert game disc first step insert game disc consol comput . follow instruct set game . step 2 . choos game onc game set , choos game 'd like play . forza motorsport ha differ mode : career , free play , arcad . thi articl , focu arcad mode . step 3 . make quick race arcad mode onc arcad mode select , choos `` quick race '' get start quickli . step 4 . pick racetrack pick racetrack differ one avail like road atlanta , new york , rio de janeiro , mapl valley , anyth choos . step 5 . pick class car forza motorsport ha differ car class , class , b , c , , r. pick class suit game style choos car like . step 6 . option panel option panel open automat choos car . press `` ok '' , patient race load . show time , wind direct , wind head , mile . step 7 . acceler acceler , press right trigger make car engin run . step 8 . go ! onc acceler complet , let go brake hit ga go ! step 9 . arrow steer , use left thumbstick turn left , move thumbstick left , turn right , move thumbstick right . step 10 . paus game paus game , press `` start '' button . feel lone want oper , choos `` ghost car '' set turn . step 11 . replay race want see well , use thi featur see video race , show turn reason . step 12 . fun enjoy game ! conclus , forza motorsport fun game impress graphic , user-friendli interfac , thrill gameplay . follow step improv gameplay fun .\"\n",
            " \"buy virtual consol game nintendo wii fun easi process net classic game play consol . simpl step , explor world classic nintendo game time . 's buy virtual consol game nintendo wii . method 1 : use wii point card 1 . find wii point card game retail like gamestop . n't alreadi , go local game retail look wii point card . usual sold increment $ 10 $ 20 come code back use add point system . 2 . make sure wii onlin secur connect possibl . 'll need internet connect access wii shop channel purchas virtual consol game . possibl , make sure consol connect secur network . 3 . open wii shop channel , click add wii point bottom right screen channel finish load . thi take screen two option : `` card '' `` credit card . '' select `` card '' proceed . 4 . click `` card . '' thi bring screen prompt enter code wii point card . 5 . , wii ask code 5 segment , separ dash . enter thi code wii . 6 . prompt , wii point ad wii , use purchas game . onc 've enter code , wii ask confirm point 're ad . prompt , point ad system . 7 . click `` virtual consol . '' onc wii point ad , select `` virtual consol '' wii shop channel 's main menu . 8 . choos want game display . choos display game list virtual shelf . pick one work best . 9 . scroll list game want . wide varieti virtual consol game avail , take time find one interest . 10 . click game want play , hit ye confirm box . thi take final confirm screen show game 's price prompt confirm purchas . 're readi buy , hit `` ye . '' 11 . wait game download . download process take sever minut , depend size game . patient let finish . 12 . bought game want play , go back wii menu . onc game ha finish download , 'll kick back wii menu . new game list among channel . 13 . select new game bought , start like regular channel . select game hit `` start . '' 're readi play ! method 2 : use credit card 1 . open wii shop channel , click add wii point . instead select `` card , '' choos `` credit card . '' thi take screen enter credit card inform . 2 . click `` credit card . '' thi bring screen enter credit card inform . 3 . key credit card number . enter credit card number , expir date , secur code . make sure thi inform accur , purchas wo n't go . 4 . let nintendo author purchas . onc 've enter inform , nintendo author purchas add appropri number point system . 5 . go back point card process abov skip step 7 . necessari wii point , follow step abov purchas download favorit virtual consol game .\"\n",
            " \"window nt 4.0 wa popular oper system back day , still prefer use today . 're look instal window nt 4.0 workstat , thi guid help get start . 1 . enter window nt 4.0 instal disc . insert window nt 4.0 instal disc comput 's cd dvd drive . comput recogn disc begin boot . 2 . press ↵ enter continu instal . onc comput ha boot , ask want continu instal window nt 4.0 . press enter key start instal process . 3 . press ⇟ pgdn key get bottom . instal file load , may see text screen ask press key continu boot cd . ignor prompt instead use page key scroll bottom text . 4 . press f8 accept term condit . get bottom text , prompt accept term condit window nt 4.0 licens agreement . read term , press f8 accept . 5 . check see abov list match specif comput . accept licens agreement , list requir comput display screen . make sure comput meet requir befor continu instal process . 6 . select partit hard drive want instal window nt 4.0 press ↵ enter . next step select partit hard drive want instal window nt 4.0 . use arrow key select partit want use , press enter confirm choic . 7 . choos file system would like partit hard drive . present choic file system use window nt 4.0 instal . choos file system would like use , continu instal process . 8 . wait process complet . instal process take time complet , patient wait finish . 9 . choos want oper system 's main file store press ↵ enter 's done . instal finish , prompt choos want oper system 's main file store . choos locat want , press enter continu . 10 . goe well see thi screen . instal process success , see screen let know window nt 4.0 ha instal . 11 . wait thi screen pop . wait setup process complet final configur screen pop . 12 . choos type setup want click next . final configur screen ask choos type setup want . make select , continu setup process . 13 . type name and/or organis click next . prompt enter name and/or organ . enter inform , continu setup process . 14 . type name comput ( anyth ) click next . prompt choos name comput . enter name choic , continu setup process . 15 . add password desir . consid ad password window nt 4.0 instal ad secur . 16 . consid ad emerg repair disk use repair window nt 4.0 someth bad occur . thi step option , creat emerg repair disk come handi ever need repair window nt 4.0 instal . 17 . choos compon prefer . ask choos prefer compon window nt 4.0 instal . make select , continu setup process . 18 . pick network prefer . prompt pick network prefer . make select , continu setup process . 19 . click finish . onc 've made select , click finish button complet window nt 4.0 instal process . 20 . make sure date , time time zone correct click close . instal process complet , make sure date , time , time zone set correct befor close setup window . 21 . ensur display set correct click ok. onc set correct , click ok button final configur . 22 . remov floppi disk cd click restart comput . final , remov ani floppi disk cd comput , click restart comput button finish instal process . 23 . press ctrl+alt+delet key order . comput restart , press ctrl+alt+delet key order log new window nt 4.0 instal . 24 . type password press ok . creat password dure instal process , enter press ok log new instal . 25 . onc present thi screen , window nt 4.0 ha fulli instal ! congratul ! success instal window nt 4.0 comput .\"\n",
            " ...\n",
            " 'author introduc semi-supervis method neural network , inspir label propag . method appear exactli one propos ( weston et al , 2008 ) ( author cite 2012 paper ) . optim object function eq ( 4 ) exactli eq ( 9 ) ( weston et al , 2008 ) . possibl novelti , author propos use adjac matrix input neural network , featur , show success blogcatalog dataset . experi text classif use neighbor accord word2vec averag embed build adjac matrix . top report accuraci convinc compar ( zhang et al , 2015 ) report perform . last experi semant intent classif , custom dataset ; neighbor also found accord word2vec metric . summari , paper propos applic origin ( weston et al , 2008 ) paper . rebrand algorithm new name , doe bring ani scientif novelti , experiment section lack exist baselin convinc .'\n",
            " 'thi paper propos neural graph machin add graph regular neural network hidden represent improv network learn take graph structur account . propos model , howev , almost ident weston et al . 2012 . author clarifi answer question , new thing previou work : 1. show graph augment train rang differ type network , includ ff , cnn , rnn etc . work rang problem . 2. graph help train better network , e.g . 3 layer cnn graph doe well 9 layer cnn 3. graph augment train work varieti differ kind graph . howev , point mention abov seem simpli differ applic graph augment train idea , observ made dure applic . think therefor proper call propos model novel model new name neural graph machin , rather make clear paper thi empir studi model propos weston et al . 2012 differ problem would accept .'\n",
            " \"paper propos model aim learn label node graph semi-supervis set . idea model base use graph structur regular represent learn node level . experiment result provid differ task underli idea thi paper ( graph regular ) ha alreadi explor differ paper – e.g 'learn latent represent node classifi heterogen social network ' [ jacob et al . 2014 ] , [ weston et al 2012 ] real graph structur use instead built one . experi lack strong comparison graph model ( e.g iter classif , 'learn label unlabel data direct graph ' , ... ) . novelti paper experiment protocol strong enough accpet paper . pro : * learn graph import topic con : * mani exist approach alreadi exploit type idea , result veri close model * lack comparison w.r.t exist model\"]\n"
          ]
        }
      ],
      "source": [
        "print(df1['content_tfidf'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mabaIWdGjKO9",
        "outputId": "4e4d54ae-ae0f-4234-d6a5-a88cc1844ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f\n"
          ]
        }
      ],
      "source": [
        "print(text[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZiJRZ59eO1e",
        "outputId": "8e5c0248-f5c5-4140-d3ac-e6c20576052f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-eV11VWjuSL"
      },
      "outputs": [],
      "source": [
        "#Hybrid Features Extraction:\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "import heapq\n",
        "\n",
        "def return_best_bi_grams(text):\n",
        "      bigrams = ngrams(text,2)\n",
        "\n",
        "      data = dict(Counter(bigrams))\n",
        "      list_ngrams = heapq.nlargest(100, data.keys(), key=lambda k: data[k])\n",
        "      return list_ngrams\n",
        "\n",
        "def return_best_tri_grams(text):\n",
        "      trigrams = ngrams(text,3)\n",
        "\n",
        "      data = dict(Counter(trigrams))\n",
        "      list_ngrams = heapq.nlargest(100, data.keys(), key=lambda k: data[k])\n",
        "      return list_ngrams\n",
        "\n",
        "def find_freq_n_gram_in_txt(text, list_bigram, list_trigram):\n",
        "\n",
        "      to_ret = []\n",
        "\n",
        "      num_bigrams = len(Counter(zip(text,text[1:])))\n",
        "      num_trigrams = len(Counter(zip(text,text[1:],text[2:])))\n",
        "\n",
        "      for n_gram in list_bigram:\n",
        "          to_ret.append(text.count(''.join(n_gram))/num_bigrams)\n",
        "\n",
        "      for n_gram in list_trigram:\n",
        "          to_ret.append(text.count(''.join(n_gram))/num_trigrams)\n",
        "\n",
        "      return to_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3rynp8L9k2h"
      },
      "outputs": [],
      "source": [
        "text = \" \".join(df1['text'].values)\n",
        "list_bigram = return_best_bi_grams(text)\n",
        "list_trigram = return_best_tri_grams(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am Surbhi\"\n",
        "num_bigrams = len(Counter(zip(text,text[1:])))\n",
        "num_trigrams = len(Counter(zip(text,text[1:],text[2:])))\n",
        "to_ret = []\n",
        "\n",
        "for n_gram in list_bigram:\n",
        "        print(n_gram)\n",
        "        print(''.join(n_gram))\n",
        "        print(text.count(''.join(n_gram)))\n",
        "        to_ret.append(text.count(''.join(n_gram))/num_bigrams)\n",
        "\n",
        "for n_gram in list_trigram:\n",
        "          to_ret.append(text.count(''.join(n_gram))/num_trigrams)\n",
        "print(to_ret)\n",
        "print(num_bigrams)\n",
        "print(num_trigrams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7uZ3wwcHX9P",
        "outputId": "d1abc420-600c-41d7-9495-78947292773c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('e', ' ')\n",
            "e \n",
            "0\n",
            "(' ', 't')\n",
            " t\n",
            "0\n",
            "('t', 'h')\n",
            "th\n",
            "0\n",
            "(' ', 'a')\n",
            " a\n",
            "1\n",
            "('s', ' ')\n",
            "s \n",
            "0\n",
            "('h', 'e')\n",
            "he\n",
            "0\n",
            "('i', 'n')\n",
            "in\n",
            "0\n",
            "('d', ' ')\n",
            "d \n",
            "0\n",
            "('n', ' ')\n",
            "n \n",
            "0\n",
            "('e', 'r')\n",
            "er\n",
            "0\n",
            "('a', 'n')\n",
            "an\n",
            "0\n",
            "('t', ' ')\n",
            "t \n",
            "0\n",
            "('r', 'e')\n",
            "re\n",
            "0\n",
            "('o', 'n')\n",
            "on\n",
            "0\n",
            "(' ', 'o')\n",
            " o\n",
            "0\n",
            "('r', ' ')\n",
            "r \n",
            "0\n",
            "(' ', 'i')\n",
            " i\n",
            "0\n",
            "(' ', 's')\n",
            " s\n",
            "0\n",
            "(',', ' ')\n",
            ", \n",
            "0\n",
            "('a', 't')\n",
            "at\n",
            "0\n",
            "('o', 'r')\n",
            "or\n",
            "0\n",
            "('t', 'i')\n",
            "ti\n",
            "0\n",
            "('e', 's')\n",
            "es\n",
            "0\n",
            "('e', 'n')\n",
            "en\n",
            "0\n",
            "('n', 'd')\n",
            "nd\n",
            "0\n",
            "('o', 'u')\n",
            "ou\n",
            "0\n",
            "('y', ' ')\n",
            "y \n",
            "0\n",
            "('t', 'e')\n",
            "te\n",
            "0\n",
            "(' ', 'c')\n",
            " c\n",
            "0\n",
            "(' ', 'w')\n",
            " w\n",
            "0\n",
            "('a', 'r')\n",
            "ar\n",
            "0\n",
            "('a', 'l')\n",
            "al\n",
            "0\n",
            "('o', ' ')\n",
            "o \n",
            "0\n",
            "('t', 'o')\n",
            "to\n",
            "0\n",
            "('n', 'g')\n",
            "ng\n",
            "0\n",
            "('i', 't')\n",
            "it\n",
            "0\n",
            "('s', 't')\n",
            "st\n",
            "0\n",
            "('i', 's')\n",
            "is\n",
            "0\n",
            "('e', 'd')\n",
            "ed\n",
            "0\n",
            "('.', ' ')\n",
            ". \n",
            "0\n",
            "(' ', 'p')\n",
            " p\n",
            "0\n",
            "('n', 't')\n",
            "nt\n",
            "0\n",
            "('f', ' ')\n",
            "f \n",
            "0\n",
            "(' ', 'b')\n",
            " b\n",
            "0\n",
            "(' ', 'f')\n",
            " f\n",
            "0\n",
            "('o', 'f')\n",
            "of\n",
            "0\n",
            "('l', 'e')\n",
            "le\n",
            "0\n",
            "('s', 'e')\n",
            "se\n",
            "0\n",
            "('l', ' ')\n",
            "l \n",
            "0\n",
            "('v', 'e')\n",
            "ve\n",
            "0\n",
            "('a', 's')\n",
            "as\n",
            "0\n",
            "('g', ' ')\n",
            "g \n",
            "0\n",
            "('a', ' ')\n",
            "a \n",
            "0\n",
            "('h', 'a')\n",
            "ha\n",
            "0\n",
            "(' ', 'm')\n",
            " m\n",
            "0\n",
            "('i', 'o')\n",
            "io\n",
            "0\n",
            "('r', 'o')\n",
            "ro\n",
            "0\n",
            "('m', 'e')\n",
            "me\n",
            "0\n",
            "('u', 'r')\n",
            "ur\n",
            "1\n",
            "('e', 'a')\n",
            "ea\n",
            "0\n",
            "('r', 'i')\n",
            "ri\n",
            "0\n",
            "('d', 'e')\n",
            "de\n",
            "0\n",
            "('i', 'c')\n",
            "ic\n",
            "0\n",
            "('r', 'a')\n",
            "ra\n",
            "0\n",
            "(' ', 'd')\n",
            " d\n",
            "0\n",
            "(' ', 'h')\n",
            " h\n",
            "0\n",
            "('c', 'o')\n",
            "co\n",
            "0\n",
            "('n', 'e')\n",
            "ne\n",
            "0\n",
            "('h', ' ')\n",
            "h \n",
            "0\n",
            "('l', 'l')\n",
            "ll\n",
            "0\n",
            "('h', 'i')\n",
            "hi\n",
            "1\n",
            "('l', 'i')\n",
            "li\n",
            "0\n",
            "(' ', 'r')\n",
            " r\n",
            "0\n",
            "('c', 'a')\n",
            "ca\n",
            "0\n",
            "(' ', 'e')\n",
            " e\n",
            "0\n",
            "(' ', 'y')\n",
            " y\n",
            "0\n",
            "('e', 'l')\n",
            "el\n",
            "0\n",
            "('s', 'i')\n",
            "si\n",
            "0\n",
            "('t', 'a')\n",
            "ta\n",
            "0\n",
            "('c', 'e')\n",
            "ce\n",
            "0\n",
            "('y', 'o')\n",
            "yo\n",
            "0\n",
            "('o', 'm')\n",
            "om\n",
            "0\n",
            "('c', 'h')\n",
            "ch\n",
            "0\n",
            "('l', 'a')\n",
            "la\n",
            "0\n",
            "('m', 'a')\n",
            "ma\n",
            "0\n",
            "(' ', 'l')\n",
            " l\n",
            "0\n",
            "('n', 's')\n",
            "ns\n",
            "0\n",
            "('b', 'e')\n",
            "be\n",
            "0\n",
            "('e', 't')\n",
            "et\n",
            "0\n",
            "('p', 'e')\n",
            "pe\n",
            "0\n",
            "('f', 'o')\n",
            "fo\n",
            "0\n",
            "('e', 'c')\n",
            "ec\n",
            "0\n",
            "('i', 'l')\n",
            "il\n",
            "0\n",
            "('a', 'c')\n",
            "ac\n",
            "0\n",
            "('d', 'i')\n",
            "di\n",
            "0\n",
            "('c', 't')\n",
            "ct\n",
            "0\n",
            "('h', 'o')\n",
            "ho\n",
            "0\n",
            "('u', 's')\n",
            "us\n",
            "0\n",
            "('p', 'r')\n",
            "pr\n",
            "0\n",
            "('t', 'r')\n",
            "tr\n",
            "0\n",
            "[0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "10\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdKHvLwgjk7D"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save list_bigram and list_trigram to a file\n",
        "with open('bigram_list.pkl', 'wb') as file:\n",
        "    pickle.dump(list_bigram, file)\n",
        "\n",
        "with open('trigram_list.pkl', 'wb') as file:\n",
        "    pickle.dump(list_trigram, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ3r2Et2OP18"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save list_bigram to Google Drive\n",
        "with open('/content/drive/MyDrive/SubtaskB/bigram_list.pkl', 'wb') as file:\n",
        "    pickle.dump(list_bigram, file)\n",
        "\n",
        "# Save list_trigram to Google Drive\n",
        "with open('/content/drive/MyDrive/SubtaskB/trigram_list.pkl', 'wb') as file:\n",
        "    pickle.dump(list_trigram, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qtcQH7Vjm9-"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Load the saved lists\n",
        "with open('/content/drive/MyDrive/SubtaskA/bigram_list.pkl', 'rb') as file:\n",
        "    list_bigram = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/MyDrive/SubtaskA/trigram_list.pkl', 'rb') as file:\n",
        "    list_trigram = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1HXh8DyiVvP",
        "outputId": "cfd18c51-69f4-4fb4-cc1f-5aa3e8bdb702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('e', ' '), (' ', 't'), ('t', 'h'), (' ', 'a'), ('s', ' '), ('h', 'e'), ('i', 'n'), ('d', ' '), ('n', ' '), ('e', 'r'), ('a', 'n'), ('t', ' '), ('r', 'e'), ('o', 'n'), (' ', 'o'), ('r', ' '), (' ', 'i'), (' ', 's'), (',', ' '), ('a', 't'), ('o', 'r'), ('t', 'i'), ('e', 's'), ('e', 'n'), ('n', 'd'), ('o', 'u'), ('y', ' '), ('t', 'e'), (' ', 'c'), (' ', 'w'), ('a', 'r'), ('a', 'l'), ('o', ' '), ('t', 'o'), ('n', 'g'), ('i', 't'), ('s', 't'), ('i', 's'), ('e', 'd'), ('.', ' '), (' ', 'p'), ('n', 't'), ('f', ' '), (' ', 'b'), (' ', 'f'), ('o', 'f'), ('l', 'e'), ('s', 'e'), ('l', ' '), ('v', 'e'), ('a', 's'), ('g', ' '), ('a', ' '), ('h', 'a'), (' ', 'm'), ('i', 'o'), ('r', 'o'), ('m', 'e'), ('u', 'r'), ('e', 'a'), ('r', 'i'), ('d', 'e'), ('i', 'c'), ('r', 'a'), (' ', 'd'), (' ', 'h'), ('c', 'o'), ('n', 'e'), ('h', ' '), ('l', 'l'), ('h', 'i'), ('l', 'i'), (' ', 'r'), ('c', 'a'), (' ', 'e'), (' ', 'y'), ('e', 'l'), ('s', 'i'), ('t', 'a'), ('c', 'e'), ('y', 'o'), ('o', 'm'), ('c', 'h'), ('l', 'a'), ('m', 'a'), (' ', 'l'), ('n', 's'), ('b', 'e'), ('e', 't'), ('p', 'e'), ('f', 'o'), ('e', 'c'), ('i', 'l'), ('a', 'c'), ('d', 'i'), ('c', 't'), ('h', 'o'), ('u', 's'), ('p', 'r'), ('t', 'r')]\n"
          ]
        }
      ],
      "source": [
        "print(list_bigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8hvwMB3iIeq",
        "outputId": "72579315-0622-41f7-97bc-3dcdb197d9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#####\n",
            "Character N-gram\n",
            "Training done, accuracy is :  0.4806666666666667\n",
            "Training done, f1-score is :  0.44013012989282435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Character N-gram only\n",
        "def tokenize_text(text):\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "print(\"#####\")\n",
        "print(\"Character N-gram\")\n",
        "feats_train = df1['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "feats_test = df2['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "\n",
        "feats_train = pd.DataFrame(feats_train)[0].apply(lambda x: pd.Series(x))\n",
        "feats_test = pd.DataFrame(feats_test)[0].apply(lambda x: pd.Series(x))\n",
        "\n",
        "#clf_char = xgb.XGBClassifier().fit(feats_train, nlp_train['Target'])\n",
        "clf_char = LogisticRegression(random_state=0).fit(feats_train, df1['label'])\n",
        "y_pred = clf_char.predict(feats_test)\n",
        "y_proba = clf_char.predict_proba(feats_test)\n",
        "y_proba_train = clf_char.predict_proba(feats_train)\n",
        "\n",
        "# Assuming y_proba and y_proba_train are NumPy arrays\n",
        "np.save('/content/drive/MyDrive/SubtaskB/y_proba.npy1', y_proba)\n",
        "np.save('/content/drive/MyDrive/SubtaskB/y_proba_train1.npy', y_proba_train)\n",
        "\n",
        "\n",
        "score_char = accuracy_score(df2['label'], y_pred)\n",
        "f1_char = f1_score(df2['label'], y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_char)\n",
        "print(\"Training done, f1-score is : \", f1_char)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(df2['label'], y_pred, average=\"macro\")\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(df2['label'], y_pred, average=\"macro\")\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(df2['label'], y_proba[:, 1])\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "id": "MsxMK3nuAR0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Character N-gram only\n",
        "def tokenize_text(text):\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "print(\"#####\")\n",
        "print(\"Character N-gram\")\n",
        "feats_train = df1['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "feats_test = test['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "\n",
        "feats_train = pd.DataFrame(feats_train)[0].apply(lambda x: pd.Series(x))\n",
        "feats_test = pd.DataFrame(feats_test)[0].apply(lambda x: pd.Series(x))\n",
        "\n",
        "#clf_char = xgb.XGBClassifier().fit(feats_train, nlp_train['Target'])\n",
        "clf_char = LogisticRegression(random_state=0).fit(feats_train, df1['label'])\n",
        "y_pred = clf_char.predict(feats_test)\n",
        "y_proba = clf_char.predict_proba(feats_test)\n",
        "y_proba_train = clf_char.predict_proba(feats_train)\n",
        "\n",
        "# Assuming y_proba and y_proba_train are NumPy arrays\n",
        "np.save('/content/drive/MyDrive/SubtaskA/y_proba_test.npy', y_proba)\n",
        "np.save('/content/drive/MyDrive/SubtaskA/y_proba_train11.npy', y_proba_train)\n",
        "\n",
        "\n",
        "score_char = accuracy_score(test['label'], y_pred)\n",
        "f1_char = f1_score(test['label'], y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_char)\n",
        "print(\"Training done, f1-score is : \", f1_char)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86glTACfIPFn",
        "outputId": "26200957-4628-40a9-a90e-6d8c8bc67409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#####\n",
            "Character N-gram\n",
            "Training done, accuracy is :  0.5804154995331466\n",
            "Training done, f1-score is :  0.5793361658778446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v5v_XoHpSRO",
        "outputId": "836a64e1-93be-4ff2-c5d6-461018f35341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      0.222785\n",
            "1      0.149367\n",
            "2      0.098734\n",
            "3      0.083544\n",
            "4      0.086076\n",
            "         ...   \n",
            "195    0.002049\n",
            "196    0.000000\n",
            "197    0.002049\n",
            "198    0.000000\n",
            "199    0.002049\n",
            "Name: 0, Length: 200, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(feats_train.iloc[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ATbZm8P1TyG"
      },
      "outputs": [],
      "source": [
        "print(\"Training BERT\")\n",
        "\n",
        "#if source == \"blog\":\n",
        "#model = ClassificationModel('bert', 'bert-base-cased', limit, config, model_long, tokenizer, args={'reprocess_input_data': True, 'overwrite_output_dir': True}, use_cuda=True)\n",
        "#else:\n",
        "model = ClassificationModel('bert', 'bert-base-cased', num_labels=limit, args={'reprocess_input_data': True, 'overwrite_output_dir': True,  'num_train_epochs' : 15}, use_cuda=True)\n",
        "model.train_model(df1[['cleaned_text', 'label']])\n",
        "\n",
        "predictions, raw_outputs = model.predict(list(df2['cleaned_text']))\n",
        "score_bert = accuracy_score(predictions, df2['label'])\n",
        "f1_bert = f1_score(predictions, df2['label'], average=\"macro\")\n",
        "predictions, raw_out_train = model.predict(list(df2['cleaned_text']))\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_bert)\n",
        "print(\"Training done, f1-score is : \", f1_bert)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Character N-gram only\n",
        "def tokenize_text(text):\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "print(\"#####\")\n",
        "print(\"Character N-gram\")\n",
        "feats_train = df1['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "feats_test = test['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "\n",
        "feats_train = pd.DataFrame(feats_train)[0].apply(lambda x: pd.Series(x))\n",
        "feats_test = pd.DataFrame(feats_test)[0].apply(lambda x: pd.Series(x))\n",
        "\n",
        "#clf_char = xgb.XGBClassifier().fit(feats_train, nlp_train['Target'])\n",
        "clf_char = LogisticRegression(random_state=0).fit(feats_train, df1['label'])\n",
        "y_pred = clf_char.predict(feats_test)\n",
        "y_proba = clf_char.predict_proba(feats_test)\n",
        "y_proba_train = clf_char.predict_proba(feats_train)\n",
        "\n",
        "# Assuming y_proba and y_proba_train are NumPy arrays\n",
        "np.save('/content/drive/MyDrive/SubtaskB/y_proba_test.npy1', y_proba)\n",
        "np.save('/content/drive/MyDrive/SubtaskB/y_proba_train11.npy', y_proba_train)\n",
        "\n",
        "\n",
        "score_char = accuracy_score(test['label'], y_pred)\n",
        "f1_char = f1_score(test['label'], y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_char)\n",
        "print(\"Training done, f1-score is : \", f1_char)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "MF1cia1RTs1d",
        "outputId": "2ee2feda-eea2-469d-a12f-491893ff99b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#####\n",
            "Character N-gram\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-784f64dc39ad>:29: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. ser.count(level=1) should use ser.groupby(level=1).count().\n",
            "  to_ret.append(text.count(''.join(n_gram))/num_bigrams)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Series.count level is only valid with a MultiIndex",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-465d717b6849>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Character N-gram\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfeats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfeats_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfeats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9566\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9567\u001b[0m         )\n\u001b[0;32m-> 9568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9570\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-465d717b6849>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Character N-gram\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfeats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfeats_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfeats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-784f64dc39ad>\u001b[0m in \u001b[0;36mfind_freq_n_gram_in_txt\u001b[0;34m(text, list_bigram, list_trigram)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mn_gram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           \u001b[0mto_ret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_bigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mn_gram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   2127\u001b[0m             )\n\u001b[1;32m   2128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Series.count level is only valid with a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Series.count level is only valid with a MultiIndex"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Character N-gram\")\n",
        "feats_train = df1['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "feats_test = test['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "\n",
        "# Convert the lists to DataFrames\n",
        "feats_train = pd.DataFrame(feats_train)\n",
        "feats_test = pd.DataFrame(feats_test)\n",
        "\n",
        "clf_char = LogisticRegression(random_state=0).fit(feats_train, df1['label'])\n",
        "y_pred = clf_char.predict(feats_test)\n",
        "y_proba = clf_char.predict_proba(feats_test)\n",
        "y_proba_train = clf_char.predict_proba(feats_train)\n",
        "\n",
        "# Save the probability arrays\n",
        "np.save('/content/drive/MyDrive/SubtaskB/y_proba_test.npy1', y_proba)\n",
        "np.save('/content/drive/MyDrive/SubtaskB/y_proba_train11.npy', y_proba_train)\n",
        "\n",
        "score_char = accuracy_score(test['label'], y_pred)\n",
        "f1_char = f1_score(test['label'], y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_char)\n",
        "print(\"Training done, f1-score is : \", f1_char)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "cTO3vK6CWs1x",
        "outputId": "f59d1c02-c4cc-4f76-83b0-c0532b3803c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character N-gram\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-784f64dc39ad>:29: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. ser.count(level=1) should use ser.groupby(level=1).count().\n",
            "  to_ret.append(text.count(''.join(n_gram))/num_bigrams)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Series.count level is only valid with a MultiIndex",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b0540af801b9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Character N-gram\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeats_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert the lists to DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9566\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9567\u001b[0m         )\n\u001b[0;32m-> 9568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9570\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-b0540af801b9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Character N-gram\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeats_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert the lists to DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-784f64dc39ad>\u001b[0m in \u001b[0;36mfind_freq_n_gram_in_txt\u001b[0;34m(text, list_bigram, list_trigram)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mn_gram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           \u001b[0mto_ret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_bigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mn_gram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   2127\u001b[0m             )\n\u001b[1;32m   2128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Series.count level is only valid with a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Series.count level is only valid with a MultiIndex"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the index of the DataFrame\n",
        "df1.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"Character N-gram\")\n",
        "feats_train = df1['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "feats_test = test['text'].apply(lambda x: find_freq_n_gram_in_txt(x, list_bigram, list_trigram)).values\n",
        "\n",
        "# Convert the lists to DataFrames\n",
        "feats_train = pd.DataFrame(feats_train)\n",
        "feats_test = pd.DataFrame(feats_test)\n",
        "\n",
        "# Train logistic regression model\n",
        "clf_char = LogisticRegression(random_state=0).fit(feats_train, df1['label'])\n",
        "y_pred = clf_char.predict(feats_test)\n",
        "y_proba = clf_char.predict_proba(feats_test)\n",
        "y_proba_train = clf_char.predict_proba(feats_train)\n",
        "\n",
        "# Save the probability arrays\n",
        "np.save('/content/drive/MyDrive/SubtaskB/y_proba_test.npy1', y_proba)\n",
        "np.save('/content/drive/MyDrive/SubtaskB/y_proba_train11.npy', y_proba_train)\n",
        "\n",
        "# Evaluate model performance\n",
        "score_char = accuracy_score(test['label'], y_pred)\n",
        "f1_char = f1_score(test['label'], y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_char)\n",
        "print(\"Training done, f1-score is : \", f1_char)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Ck9hmLR3chOI",
        "outputId": "54735611-6528-43c1-a95b-0b05315ea179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character N-gram\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-784f64dc39ad>:29: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. ser.count(level=1) should use ser.groupby(level=1).count().\n",
            "  to_ret.append(text.count(''.join(n_gram))/num_bigrams)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Series.count level is only valid with a MultiIndex",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-383bd198e252>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Character N-gram\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfeats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfeats_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convert the lists to DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9566\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9567\u001b[0m         )\n\u001b[0;32m-> 9568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9570\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-383bd198e252>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Character N-gram\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfeats_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfeats_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_freq_n_gram_in_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convert the lists to DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-784f64dc39ad>\u001b[0m in \u001b[0;36mfind_freq_n_gram_in_txt\u001b[0;34m(text, list_bigram, list_trigram)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mn_gram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_bigram\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           \u001b[0mto_ret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_bigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mn_gram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_trigram\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   2127\u001b[0m             )\n\u001b[1;32m   2128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Series.count level is only valid with a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Series.count level is only valid with a MultiIndex"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def find_freq_n_gram_in_txt(text, list_bigram, list_trigram):\n",
        "    to_ret = []\n",
        "\n",
        "    num_bigrams = len(Counter(zip(text, text[1:])))\n",
        "    num_trigrams = len(Counter(zip(text, text[1:], text[2:])))\n",
        "\n",
        "    for n_gram in list_bigram:\n",
        "        to_ret.append(text.count(''.join(n_gram)) / num_bigrams)\n",
        "\n",
        "    if num_trigrams > 0:  # Check if num_trigrams is greater than zero to avoid division by zero\n",
        "        for n_gram in list_trigram:\n",
        "            to_ret.append(text.count(''.join(n_gram)) / num_trigrams)\n",
        "\n",
        "    return to_ret"
      ],
      "metadata": {
        "id": "U5mq2mqci_G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text values as a list\n",
        "texts_train = df1['text'].tolist()\n",
        "# Extract text values as a list\n",
        "texts_test = test['text'].values.tolist()\n",
        "\n",
        "\n",
        "# Apply the function to each text individually\n",
        "feats_train = [find_freq_n_gram_in_txt(text, list_bigram, list_trigram) for text in texts_train]\n",
        "feats_test = [find_freq_n_gram_in_txt(text, list_bigram, list_trigram) for text in texts_test]\n",
        "\n",
        "# Convert the lists to DataFrames\n",
        "feats_train = pd.DataFrame(feats_train)\n",
        "feats_test = pd.DataFrame(feats_test)\n",
        "print(feats_test)\n",
        "\n",
        "# # Train logistic regression model\n",
        "# clf_char = LogisticRegression(random_state=0).fit(feats_train, df1['label'])\n",
        "# y_pred = clf_char.predict(feats_test)\n",
        "# y_proba = clf_char.predict_proba(feats_test)\n",
        "# y_proba_train = clf_char.predict_proba(feats_train)\n",
        "\n",
        "# # Save the probability arrays\n",
        "# np.save('/content/drive/MyDrive/SubtaskB/y_proba_test.npy1', y_proba)\n",
        "# np.save('/content/drive/MyDrive/SubtaskB/y_proba_train11.npy', y_proba_train)\n",
        "\n",
        "# # Evaluate model performance\n",
        "# score_char = accuracy_score(test['label'], y_pred)\n",
        "# f1_char = f1_score(test['label'], y_pred, average=\"macro\")\n",
        "\n",
        "# print(\"Training done, accuracy is : \", score_char)\n",
        "# print(\"Training done, f1-score is : \", f1_char)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3BCXXaDceoc6",
        "outputId": "7ff78afe-1e1f-4b66-fe1b-0fe624d1d7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2920b727f3d4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract text values as a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtexts_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Extract text values as a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtexts_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "Gw9GHdL5G5wh",
        "outputId": "20a09880-284a-4d81-b9f9-c499ba8256cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e1055976-6362-40e4-afaf-f9cb2175a649\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>model</th>\n",
              "      <th>source</th>\n",
              "      <th>id</th>\n",
              "      <th>content_tfidf</th>\n",
              "      <th>avg_len</th>\n",
              "      <th>len_text</th>\n",
              "      <th>len_words</th>\n",
              "      <th>...</th>\n",
              "      <th>f_e_3</th>\n",
              "      <th>f_e_4</th>\n",
              "      <th>f_e_5</th>\n",
              "      <th>f_e_6</th>\n",
              "      <th>f_e_7</th>\n",
              "      <th>f_e_8</th>\n",
              "      <th>f_e_9</th>\n",
              "      <th>f_e_10</th>\n",
              "      <th>f_e_11</th>\n",
              "      <th>richness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Forza Motorsport is a popular racing game that...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>0</td>\n",
              "      <td>forza motorsport popular race game provid play...</td>\n",
              "      <td>4.457002</td>\n",
              "      <td>2244.0</td>\n",
              "      <td>407.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015152</td>\n",
              "      <td>0.014706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.577396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Buying Virtual Console games for your Nintendo...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>1</td>\n",
              "      <td>buy virtual consol game nintendo wii fun easi ...</td>\n",
              "      <td>4.418502</td>\n",
              "      <td>3728.0</td>\n",
              "      <td>681.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017972</td>\n",
              "      <td>0.006706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003219</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.427313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Windows NT 4.0 was a popular operating system ...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>2</td>\n",
              "      <td>window nt 4.0 wa popular oper system back day ...</td>\n",
              "      <td>4.709748</td>\n",
              "      <td>5237.0</td>\n",
              "      <td>913.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020432</td>\n",
              "      <td>0.005728</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001146</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.346112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>How to Make Perfume\\n\\nPerfume is a great way ...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>3</td>\n",
              "      <td>make perfum perfum great way enhanc person sce...</td>\n",
              "      <td>4.772277</td>\n",
              "      <td>4729.0</td>\n",
              "      <td>808.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014168</td>\n",
              "      <td>0.005709</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001269</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002326</td>\n",
              "      <td>0.002326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.407178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>How to Convert Song Lyrics to a Song'\\n\\nConve...</td>\n",
              "      <td>1</td>\n",
              "      <td>chatGPT</td>\n",
              "      <td>wikihow</td>\n",
              "      <td>4</td>\n",
              "      <td>convert song lyric song' convert song lyric fu...</td>\n",
              "      <td>4.407733</td>\n",
              "      <td>3095.0</td>\n",
              "      <td>569.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.012601</td>\n",
              "      <td>0.008401</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.427065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 62 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1055976-6362-40e4-afaf-f9cb2175a649')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1055976-6362-40e4-afaf-f9cb2175a649 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1055976-6362-40e4-afaf-f9cb2175a649');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97ad6ca0-48a0-417a-bbc8-b1399cfbfdc5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97ad6ca0-48a0-417a-bbc8-b1399cfbfdc5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97ad6ca0-48a0-417a-bbc8-b1399cfbfdc5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  label  \\\n",
              "0           0  Forza Motorsport is a popular racing game that...      1   \n",
              "1           1  Buying Virtual Console games for your Nintendo...      1   \n",
              "2           2  Windows NT 4.0 was a popular operating system ...      1   \n",
              "3           3  How to Make Perfume\\n\\nPerfume is a great way ...      1   \n",
              "4           4  How to Convert Song Lyrics to a Song'\\n\\nConve...      1   \n",
              "\n",
              "     model   source  id                                      content_tfidf  \\\n",
              "0  chatGPT  wikihow   0  forza motorsport popular race game provid play...   \n",
              "1  chatGPT  wikihow   1  buy virtual consol game nintendo wii fun easi ...   \n",
              "2  chatGPT  wikihow   2  window nt 4.0 wa popular oper system back day ...   \n",
              "3  chatGPT  wikihow   3  make perfum perfum great way enhanc person sce...   \n",
              "4  chatGPT  wikihow   4  convert song lyric song' convert song lyric fu...   \n",
              "\n",
              "    avg_len  len_text  len_words  ...     f_e_3     f_e_4     f_e_5  f_e_6  \\\n",
              "0  4.457002    2244.0      407.0  ...  0.000000  0.015152  0.014706    0.0   \n",
              "1  4.418502    3728.0      681.0  ...  0.000000  0.017972  0.006706    0.0   \n",
              "2  4.709748    5237.0      913.0  ...  0.000000  0.020432  0.005728    0.0   \n",
              "3  4.772277    4729.0      808.0  ...  0.000000  0.014168  0.005709    0.0   \n",
              "4  4.407733    3095.0      569.0  ...  0.000646  0.012601  0.008401    0.0   \n",
              "\n",
              "      f_e_7     f_e_8     f_e_9    f_e_10  f_e_11  richness  \n",
              "0  0.000891  0.000000  0.000000  0.000000     0.0  0.577396  \n",
              "1  0.003219  0.000000  0.000000  0.000000     0.0  0.427313  \n",
              "2  0.001146  0.000382  0.000191  0.000191     0.0  0.346112  \n",
              "3  0.001269  0.000000  0.002326  0.002326     0.0  0.407178  \n",
              "4  0.003877  0.000000  0.000646  0.000646     0.0  0.427065  \n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX5vBjBKEalu"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Assuming `model` is your fine-tuned RoBERTa model\n",
        "# Assuming `tokenizer` is the corresponding tokenizer\n",
        "\n",
        "# Load your data\n",
        "# Assuming `nlp_train` and `nlp_dev` are your training and development datasets\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model = RobertaForSequenceClassification.from_pretrained('/content/drive/My Drive/fine_tuned_model/')\n",
        "tokenizer = RobertaTokenizer.from_pretrained('/content/drive/My Drive/fine_tuned_model/')\n",
        "\n",
        "\n",
        "model.eval()\n",
        "# Function to get logits\n",
        "def get_logits(texts):\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    return logits\n",
        "\n",
        "# Get logits for training and dev data\n",
        "train_logits = get_logits(list(df1['content_tfidf']))\n",
        "dev_logits = get_logits(list(df2['content_tfidf']))\n",
        "\n",
        "# Tokenize and convert the data to tensors\n",
        "# train_inputs = tokenizer(list(df1['content_tfidf']), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "# dev_inputs = tokenizer(list(df2['content_tfidf']), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "\n",
        "# # Forward pass to get the logits\n",
        "# with torch.no_grad():\n",
        "#     train_logits = model(**train_inputs).logits\n",
        "#     dev_logits = model(**dev_inputs).logits\n",
        "\n",
        "# Save the logits to files\n",
        "torch.save(train_logits, '/content/drive/MyDrive/SubtaskA/train_logits.pt')\n",
        "torch.save(dev_logits, '/content/drive/MyDrive/SubtaskA/dev_logits.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "cnSmugA5i525",
        "outputId": "c06f8e78-b4c8-4a61-f97f-5c06d79a6756"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f43d41278df8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRobertaForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/fine_tuned_model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from math import ceil\n",
        "# Set the model to evaluation mode\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import torch\n",
        "model = RobertaForSequenceClassification.from_pretrained('/content/drive/My Drive/fine_tuned_model/')\n",
        "tokenizer = RobertaTokenizer.from_pretrained('/content/drive/My Drive/fine_tuned_model/')\n",
        "\n",
        "\n",
        "\n",
        "def process_in_batches(texts, batch_size):\n",
        "    num_batches = ceil(len(texts) / batch_size)\n",
        "    all_logits = []\n",
        "    for i in range(num_batches):\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = (i + 1) * batch_size\n",
        "        batch_texts = texts[start_idx:end_idx]\n",
        "\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            logits = model(**inputs).logits\n",
        "        all_logits.append(logits)\n",
        "\n",
        "    return torch.cat(all_logits, dim=0)\n",
        "\n",
        "# Assuming df1['content_tfidf'] and df2['content_tfidf'] are lists of texts\n",
        "batch_size = 4  # Adjust this based on your available memory\n",
        "\n",
        "# Get logits for training data in batches\n",
        "train_logits = process_in_batches(list(df1['content_tfidf']), batch_size)\n",
        "\n",
        "# Get logits for dev data in batches\n",
        "dev_logits = process_in_batches(list(df2['content_tfidf']), batch_size)\n",
        "\n",
        "# Save the logits to files\n",
        "torch.save(train_logits, '/content/drive/MyDrive/SubtaskA/train_logits.pt')\n",
        "torch.save(dev_logits, '/content/drive/MyDrive/SubtaskA/dev_logits.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0hDGYul1NYI"
      },
      "outputs": [],
      "source": [
        "# Model Combination(BERT+STYLE)\n",
        "\n",
        "print(\"#####\")\n",
        "print(\"Model combination\")\n",
        "\n",
        "feat_for_BERT_LR_train = np.concatenate([raw_out_train, y_proba_train], axis=1)\n",
        "feat_for_BERT_LR_test = np.concatenate([raw_outputs, y_proba], axis=1)\n",
        "\n",
        "clf = LogisticRegression(random_state=0).fit(feat_for_BERT_LR_train, df1['label'])\n",
        "#clf = xgb.XGBClassifier().fit(feat_for_BERT_LR_train, nlp_train['Target'])\n",
        "\n",
        "y_pred = clf.predict(feat_for_BERT_LR_test)\n",
        "score_comb = accuracy_score(df2['label'], y_pred)\n",
        "f1_comb = f1_score(df2['label'], y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_comb)\n",
        "print(\"Training done, f1-score is : \", f1_comb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNcSbOhM1frn"
      },
      "outputs": [],
      "source": [
        "# BERT + Style + Char N-gram\n",
        "\n",
        "print(\"#####\")\n",
        "print(\"BERT + Style + Char N-gram\")\n",
        "\n",
        "feat_for_BERT_full_train = np.concatenate([feat_for_BERT_LR_train, y_proba_train], axis=1)\n",
        "feat_for_BERT_full_test = np.concatenate([feat_for_BERT_LR_test, y_proba], axis=1)\n",
        "\n",
        "#clf = xgb.XGBClassifier().fit(feat_for_BERT_full_train, nlp_train['Target'])\n",
        "clf = LogisticRegression(random_state=0).fit(feat_for_BERT_full_train, df1['label'])\n",
        "\n",
        "y_pred = clf.predict(feat_for_BERT_full_test)\n",
        "score_comb_fin = accuracy_score(df2['label'], y_pred)\n",
        "f1_comb_fin = f1_score(df2['label'], y_pred, average=\"macro\")\n",
        "print(\"Training done, accuracy is : \", score_comb_fin)\n",
        "print(\"Training done, f1-score is : \", f1_comb_fin)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "\n",
        "# Specify the path to your drive folder\n",
        "drive_folder = '/content/drive/MyDrive/'\n",
        "\n",
        "# Load predicted probabilities for test set\n",
        "test_file_path = os.path.join(drive_folder, 'SubtaskA', 'logitslisttestnotrefined.pkl')\n",
        "with open(test_file_path, 'rb') as f:\n",
        "    raw_outputs1 = pickle.load(f)\n",
        "\n",
        "# Convert raw_outputs1 to a PyTorch tensor\n",
        "raw_outputs1 = torch.tensor(raw_outputs1)\n",
        "\n",
        "raw_outputs = F.softmax(raw_outputs1, dim=1)\n",
        "\n",
        "# Load predicted probabilities for training set\n",
        "train_file_path = os.path.join(drive_folder, 'SubtaskA', 'train_logitsrefined.pkl')\n",
        "with open(train_file_path, 'rb') as f:\n",
        "    raw_out_train1 = pickle.load(f)\n",
        "\n",
        "# Convert raw_out_train1 to a PyTorch tensor\n",
        "raw_out_train1 = torch.tensor(raw_out_train1)\n",
        "\n",
        "raw_out_train = F.softmax(raw_out_train1, dim=1)"
      ],
      "metadata": {
        "id": "fNB0UxI0RIme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved arrays\n",
        "import numpy as np\n",
        "y_proba = np.load('/content/drive/MyDrive/SubtaskA/y_proba_test.npy')\n",
        "y_proba_train = np.load('/content/drive/MyDrive/SubtaskA/y_proba_train11.npy')\n"
      ],
      "metadata": {
        "id": "qS6wxcc-Qh_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Combination(BERT+STYLE)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "print(\"#####\")\n",
        "print(\"Model combination\")\n",
        "\n",
        "feat_for_BERT_LR_train = np.concatenate([raw_out_train, y_proba_train], axis=1)\n",
        "feat_for_BERT_LR_test = np.concatenate([raw_outputs, y_proba], axis=1)\n",
        "# # Scale the features\n",
        "# scaler = StandardScaler()\n",
        "# scaled_feat_for_BERT_LR_train = scaler.fit_transform(feat_for_BERT_LR_train)\n",
        "# scaled_feat_for_BERT_LR_test = scaler.transform(feat_for_BERT_LR_test)\n",
        "\n",
        "\n",
        "clf = LogisticRegression(random_state=0).fit(feat_for_BERT_LR_train, df1['label'])\n",
        "#clf = xgb.XGBClassifier().fit(feat_for_BERT_LR_train, nlp_train['Target'])\n",
        "\n",
        "y_pred = clf.predict(feat_for_BERT_LR_test)\n",
        "\n",
        "\n",
        "# # Assuming you have predictions in y_pred\n",
        "# # Create a list of dictionaries for the JSONL file\n",
        "# predictions_list = [{\"id\": text_id, \"label\": int(predicted_label)} for text_id, predicted_label in zip(df2['id'], y_pred)]\n",
        "\n",
        "# # Specify the path for the JSONL file\n",
        "# jsonl_file_path = '/content/drive/MyDrive/SubtaskB/predictionsbertsylenotrefinedTESTano.jsonl'\n",
        "\n",
        "# # Write the list of dictionaries to the JSONL file\n",
        "# with open(jsonl_file_path, 'w') as jsonl_file:\n",
        "#     for entry in predictions_list:\n",
        "#         jsonl_file.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "# print(\"Prediction file saved at:\", jsonl_file_path)\n",
        "score_comb = accuracy_score(test['label'], y_pred)\n",
        "f1_comb = f1_score(test['label'], y_pred, average=\"macro\")\n",
        "\n",
        "print(\"Training done, accuracy is : \", score_comb)\n",
        "print(\"Training done, f1-score is : \", f1_comb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjBzo-0hRSKW",
        "outputId": "a0ada293-0ede-4078-edd8-53170aa46cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#####\n",
            "Model combination\n",
            "Training done, accuracy is :  0.7314133986928104\n",
            "Training done, f1-score is :  0.7216804285321834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT + Style + Char N-gram\n",
        "import json\n",
        "\n",
        "print(\"#####\")\n",
        "print(\"BERT + Style + Char N-gram\")\n",
        "\n",
        "feat_for_BERT_full_train = np.concatenate([feat_for_BERT_LR_train, y_proba_train], axis=1)\n",
        "feat_for_BERT_full_test = np.concatenate([feat_for_BERT_LR_test, y_proba], axis=1)\n",
        "\n",
        "#clf = xgb.XGBClassifier().fit(feat_for_BERT_full_train, nlp_train['Target'])\n",
        "clf = LogisticRegression(random_state=0).fit(feat_for_BERT_full_train, df1['label'])\n",
        "\n",
        "y_pred = clf.predict(feat_for_BERT_full_test)\n",
        "\n",
        "# # Assuming you have predictions in y_pred\n",
        "# # Create a list of dictionaries for the JSONL file\n",
        "# predictions_list = [{\"id\": text_id, \"label\": int(predicted_label)} for text_id, predicted_label in zip(df2['id'], y_pred)]\n",
        "\n",
        "# # Specify the path for the JSONL file\n",
        "# jsonl_file_path = '/content/drive/MyDrive/SubtaskB/predictionsbertstylecharnotrefinedTESTano.jsonl'\n",
        "\n",
        "# # Write the list of dictionaries to the JSONL file\n",
        "# with open(jsonl_file_path, 'w') as jsonl_file:\n",
        "#     for entry in predictions_list:\n",
        "#         jsonl_file.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "# print(\"Prediction file saved at:\", jsonl_file_path)\n",
        "score_comb_fin = accuracy_score(test['label'], y_pred)\n",
        "f1_comb_fin = f1_score(test['label'], y_pred, average=\"macro\")\n",
        "print(\"Training done, accuracy is : \", score_comb_fin)\n",
        "print(\"Training done, f1-score is : \", f1_comb_fin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0Mgy1QRPrEa",
        "outputId": "7dc36c59-7470-464a-8ed9-391d28785d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#####\n",
            "BERT + Style + Char N-gram\n",
            "Training done, accuracy is :  0.7312091503267973\n",
            "Training done, f1-score is :  0.7214845203332236\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}